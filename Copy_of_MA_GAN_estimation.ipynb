{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/Copy_of_MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "1d2ecc5a-7c43-44b1-fb73-d09fdf8d79ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0\n",
        "!pip install -q pyyaml h5py\n",
        "!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.16.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - LÃ¤nge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 4       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "def make_zero(x):\n",
        "  return tf.keras.backend.zeros(shape=x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))\n",
        "  \n",
        "  \n",
        "  \n",
        "train_SNR_dB = 7\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "#zero_initial = tf.keras.initializers.Zeros()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "9592108e-e586-4f75-c3be-692c662b54b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "#\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(input):\n",
        "  G_n = tf.random.normal([tf.shape(input)[0],n])  #create noise directly within the generator  \n",
        "  return G_n\n",
        "    \n",
        "tf.print(generator_noise(x))\n",
        "\n",
        "#def get_generator(input = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#,input_shape=((2*n,))))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "#  return model\n",
        "\n",
        "\n",
        "#input1 = tf.keras.layers.Input(shape=(n,))\n",
        "#x1 = tf.keras.layers.Dense(n, activation='relu')(input1)\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "#subtracted = tf.keras.layers.Concatenate(-1)([x1, x2])\n",
        "#h1 = tf.keras.layers.Dense(32)(subtracted)\n",
        "#h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "#out = tf.keras.layers.Dense(n, use_bias= False, activation='relu')(h2)\n",
        "\n",
        "input1 = tf.keras.layers.Input(shape=(n,))\n",
        "x1 = tf.keras.layers.Dense(n, activation='relu')(input1)\n",
        "input2 = tf.keras.layers.Lambda(generator_noise)(input1)\n",
        "x2 = tf.keras.layers.Dense(n, activation='relu')(input2)\n",
        "subtracted = tf.keras.layers.Concatenate(-1)([x1, x2])\n",
        "h1 = tf.keras.layers.Dense(32)(subtracted)\n",
        "h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "out = tf.keras.layers.Dense(n, use_bias= False, activation='relu')(h2)\n",
        "\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#generator = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n",
        "generator = tf.keras.models.Model(inputs=[input1], outputs=out)\n",
        "generator.summary()\n",
        "#print(x.shape,(generator_noise(x)).shape)\n",
        "print = generator([x])\n",
        "#test = generator(x)\n",
        "#print(test[1])\n",
        "generator.input\n",
        "#model.input"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.76088703 -0.2364081 -0.213842243 1.24733889]\n",
            " [0.243670672 0.429471046 -0.535788 -0.576478124]\n",
            " [-0.0634631962 0.903216064 -0.375534832 0.35452646]\n",
            " ...\n",
            " [-0.327276736 0.8765167 -0.628130317 0.414870143]\n",
            " [1.64387071 -0.203103319 -0.824779034 0.467101187]\n",
            " [0.308417767 -0.838102341 -0.715670943 1.29892051]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 4)            0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            128         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,512\n",
            "Trainable params: 1,512\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "ec9a1410-fe97-42ba-8cd7-d8eb6741f04c"
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu',input_shape=((2*n,))))\n",
        " # model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False, activation='relu'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "discriminator.summary()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, Ã¼berhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "692e5a68-4e50-4de2-c888-ddee0ea6ca2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  \n",
        "fake_training_data = tf.concat(values=[generator([x]),x], axis=-1)# training =True),x], axis=-1)\n",
        "\n",
        "tf.print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "tf.print(fake_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 8]) TensorShape([1000, 8])\n",
            "[[0.0446735024]\n",
            " [0.173898727]\n",
            " [0.232833132]\n",
            " ...\n",
            " [0.0903321654]\n",
            " [0.11226356]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def discriminator_loss(real_output, fake_output):\n",
        "  #loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#  loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #Wasserstein GAN\n",
        "#  return loss\n",
        "\n",
        "def generator_loss(fake_output, generator):\n",
        "  return -tf.reduce_mean(fake_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCZBgwYBNYW",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8J9r3UpBNl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)           #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)      #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg4uj-bbrE4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e7e38717-5b81-44d8-935d-fff981d0431f"
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  \n",
        "fake_training_data = tf.concat(values=[generator([x]),x], axis=1)# training =True),x], axis=-1)\n",
        "\n",
        "tf.print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "generator.inputs"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 8]) TensorShape([1000, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'input_1:0' shape=(None, 4) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=1000):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator([x]), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 2\n",
        "  \n",
        "  inputs_ = tf.concat(values=[inputs, inputs],  axis=-1)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=1)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=1)\n",
        "  inputs_hist = np.mean(inputs_,axis=1)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  \n",
        "  fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  plt.hist(fake_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "steps_per_epoches = 100\n",
        "batch_size = 1000\n",
        "\n",
        "evaluation_per_epochs = 200\n",
        "\n",
        "noise_dim = n        #noch Ã¤ndern wenn ich noise Ã¤ndere\n",
        "num_examples_to_generate = 16\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUTZng_fFBk",
        "colab_type": "text"
      },
      "source": [
        "# Wasserstein clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFEdt29fEj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in discriminator.trainable_variables]\n",
        "\n",
        "#def get_disc_grad(trainable_variables):\n",
        "#  return [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in trainable_variables]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "    train_step(epoch, steps_per_epoches , batch_size, generator, discriminator) \n",
        "    #if counter%5 == 0:\n",
        "    #  print(\"counter %d:\" % (counter))\n",
        "    if counter%2 == 0 and counter<3:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    if counter%100 == 0:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)  \n",
        "    #print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "      tf.print ('Time for epoch {},'.format(epoch + 1))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    real_c = real_channel(x)\n",
        "    fake_c = generator([x])\n",
        "    if tf.math.is_nan(fake_c[1,1]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message generator',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        " # print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_step(epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    \n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "      fake_training_data = tf.concat(values=[generator([x]),x], axis=1)# training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data)#, training=True)\n",
        "      fake_output = discriminator(fake_training_data)#, training=True)\n",
        "      disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.debugging.check_numerics(disc_loss,'loss generator',name=None)\n",
        "          \n",
        "    clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in discriminator.trainable_variables]\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss,clip_D)\n",
        "    tf.summary.histogram(name=None, data=real_output)\n",
        "    \n",
        "      \n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aly55MFqoMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.inputs\n",
        "generator.optimizer\n",
        "#discriminator.inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size, generator, discriminator)\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator([x])\n",
        "\n",
        "tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7ElCI1R7NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschrÃ¤nken. Jedoch soll **end-to-end** trainiert werden, hierfÃ¼r sollte vllt eine art Funktion eingesetzt werden, welche Ã¼ber die GAN's Layer zurÃ¼ck geht.\n",
        "Muss ich hierfÃ¼r die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klÃ¤ren: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "  return model\n",
        "\n",
        "def get_decoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "encoder = get_encoder()\n",
        "decoder = get_decoder()\n",
        "\n",
        "encoder.summary()\n",
        "generator.summary()\n",
        "decoder.summary()\n",
        "   \n",
        "def get_AE(encoder, generator, decoder):\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(encoder)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(decoder)\n",
        "  return AE_model\n",
        "\n",
        "#def test_Model(x):\n",
        "#  y = encoder(x)\n",
        "#  y = generator([y,make_zero(y)])\n",
        "#  y = decoder(y)\n",
        "#  return y\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  tf.print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(10000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE(encoder, generator, decoder)\n",
        "AE.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = AE.fit(data, data, batch_size=5000,steps_per_epoch=1000, epochs=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y,make_zero(x))\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sum(diff_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8o3nqP_0OTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= AE.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLzQO7yQnP1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_baseline = 'models/ae_baseline_k_{}_n_{}'.format(k,n)\n",
        "\n",
        "ae_baseline = AE(k,n,useGAN=False,seed=seed)\n",
        "ae_baseline.train(training_params, validation_params)\n",
        "\n",
        "ae_baseline.save(model_file_baseline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}