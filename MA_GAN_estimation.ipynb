{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "9dc35b53-de77-4357-8725-c1dacc9648cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-rc0\n",
        "!pip install -q pyyaml h5py\n",
        "#!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.0.0rc0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.16.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0a20190806)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc0) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (0.15.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - LÃ¤nge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**n\n",
        "n = 2       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "8cae10bb-fb75-475d-afed-8dafdfc99c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(input):\n",
        "  G_n = tf.random.normal([tf.shape(input)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "  inputs = tf.concat(values=[input, G_n], axis=1)\n",
        "  return inputs\n",
        "    \n",
        "def generator(x = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True,activation='relu'))#, input_shape=(2*n,))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "generator= generator()\n",
        "test = generator(x)\n",
        "print(test[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.4353662 0.5399398], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 8\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu',input_shape=((2*n,))))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False,kernel_initializer=randN_initial, activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, Ã¼berhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "266b497a-f55f-4097-8f69-6840ad34abeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  \n",
        "fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=-1)\n",
        "\n",
        "print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "print(fake_output[1])\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (100, 4)\n",
            "tf.Tensor([0.49976096], shape=(1,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "  return loss\n",
        "  \n",
        "def generator_loss(fake_output, generator):\n",
        "  loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "  return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCZBgwYBNYW",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8J9r3UpBNl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)           #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt74pHV7ovDx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=100):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator(x), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 2\n",
        "  \n",
        "  inputs_ = tf.concat(values=[inputs, inputs],  axis=-1)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=1)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=1)\n",
        "  inputs_hist = np.mean(inputs_,axis=1)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  \n",
        "  fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  plt.hist(fake_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 40\n",
        "steps_per_epoches = 50\n",
        "batch_size = 100\n",
        "\n",
        "evaluation_per_epochs = 100\n",
        "\n",
        "noise_dim = n        #noch Ã¤ndern wenn ich noise Ã¤ndere\n",
        "num_examples_to_generate = 16\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "    train_step(epoch, steps_per_epoches , batch_size, generator, discriminator) \n",
        "    #if counter%5 == 0:\n",
        "    #  print(\"counter %d:\" % (counter))\n",
        "    if counter%10 == 0:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    real_c = real_channel(x)\n",
        "    fake_c = generator(x)\n",
        "    if tf.math.is_nan(fake_c[1,1]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message generator',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        " # print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "\n",
        "def train_step(epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "\n",
        "    \n",
        "  for j in range(steps_per_epoches):\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data, training=True)\n",
        "      fake_output = discriminator(fake_training_data, training=True)\n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #print(disc_loss, gen_loss)\n",
        "          \n",
        "    \n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      \n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "4740769a-625a-4cd8-e624-61a1a430cd2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size, generator, discriminator)\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 29.95683765411377 sec,\n",
            "Time for epoch 2 is 17.047779321670532 sec,\n",
            "Time for epoch 3 is 16.72801947593689 sec,\n",
            "Time for epoch 4 is 17.015263080596924 sec,\n",
            "Time for epoch 5 is 17.03099274635315 sec,\n",
            "Time for epoch 6 is 15.89990782737732 sec,\n",
            "Time for epoch 7 is 17.39246678352356 sec,\n",
            "Time for epoch 8 is 17.82916021347046 sec,\n",
            "Time for epoch 9 is 15.53817367553711 sec,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nApT2WZMw8CdCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 10 is 27.141000747680664 sec,\n",
            "Time for epoch 11 is 18.181702613830566 sec,\n",
            "Time for epoch 12 is 15.612860441207886 sec,\n",
            "Time for epoch 13 is 19.447410583496094 sec,\n",
            "Time for epoch 14 is 16.16849446296692 sec,\n",
            "Time for epoch 15 is 15.956489562988281 sec,\n",
            "Time for epoch 16 is 15.886908292770386 sec,\n",
            "Time for epoch 17 is 20.063311100006104 sec,\n",
            "Time for epoch 18 is 15.655693292617798 sec,\n",
            "Time for epoch 19 is 15.944725751876831 sec,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhgFNwiIoFRcIuIBOb/AfRlVdHg5cHtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4NeHz0Q3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 20 is 27.378380060195923 sec,\n",
            "Time for epoch 21 is 20.62799835205078 sec,\n",
            "Time for epoch 22 is 15.807929277420044 sec,\n",
            "Time for epoch 23 is 15.449279069900513 sec,\n",
            "Time for epoch 24 is 15.638895273208618 sec,\n",
            "Time for epoch 25 is 15.586712121963501 sec,\n",
            "Time for epoch 26 is 15.571332693099976 sec,\n",
            "Time for epoch 27 is 22.07239556312561 sec,\n",
            "Time for epoch 28 is 15.730287551879883 sec,\n",
            "Time for epoch 29 is 15.665331363677979 sec,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmP8P+IpkEcpFQSgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnPjNzDLGid/MLGOc+M3MMsaJ38wsY/4/G/JnK6MvEkYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 30 is 27.64129948616028 sec,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n",
            "Time for the training is 28.29481077194214 sec,\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  160       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  64        \n",
            "=================================================================\n",
            "Total params: 1,280\n",
            "Trainable params: 1,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 192\n",
            "Trainable params: 192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 9min 4s, sys: 11 s, total: 9min 15s\n",
            "Wall time: 9min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3e9b7f1-7dd8-4081-8cd1-048c72502e49"
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator(x)\n",
        "\n",
        "tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=1676059, shape=(100, 2), dtype=float32, numpy=\n",
              "array([[0.0000000e+00, 3.8743019e-07],\n",
              "       [0.0000000e+00, 1.7881393e-07],\n",
              "       [0.0000000e+00, 9.9993837e-01],\n",
              "       [0.0000000e+00, 2.8431416e-05],\n",
              "       [8.9406967e-08, 3.4583956e-02],\n",
              "       [5.9604645e-08, 1.3411045e-06],\n",
              "       [0.0000000e+00, 2.0027167e-01],\n",
              "       [0.0000000e+00, 1.4901161e-07],\n",
              "       [0.0000000e+00, 2.6822090e-07],\n",
              "       [0.0000000e+00, 2.4254620e-03],\n",
              "       [2.9802322e-07, 1.4364719e-04],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [2.9802322e-08, 7.4803829e-06],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 2.9802322e-08],\n",
              "       [2.6822090e-07, 2.8565526e-04],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [1.1920929e-07, 4.9613595e-02],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 9.9980688e-01],\n",
              "       [0.0000000e+00, 8.9406967e-08],\n",
              "       [0.0000000e+00, 2.0861626e-07],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [1.1920929e-07, 8.2895780e-01],\n",
              "       [0.0000000e+00, 5.9604645e-08],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 1.4305115e-06],\n",
              "       [1.7881393e-07, 2.2739172e-05],\n",
              "       [8.6426735e-07, 3.7759840e-03],\n",
              "       [2.9802322e-08, 3.4868717e-06],\n",
              "       [0.0000000e+00, 3.5762787e-07],\n",
              "       [5.9604645e-08, 2.4050474e-05],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [6.5565109e-07, 9.8111671e-01],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 2.0265579e-06],\n",
              "       [2.9802322e-08, 8.2343817e-05],\n",
              "       [0.0000000e+00, 3.2782555e-07],\n",
              "       [8.9406967e-08, 5.7518482e-06],\n",
              "       [0.0000000e+00, 5.8114529e-06],\n",
              "       [0.0000000e+00, 2.3841858e-06],\n",
              "       [1.1026859e-05, 3.5189092e-03],\n",
              "       [2.4735928e-06, 3.7410259e-03],\n",
              "       [0.0000000e+00, 2.5242567e-05],\n",
              "       [0.0000000e+00, 9.9887455e-01],\n",
              "       [4.4703484e-07, 4.5031309e-05],\n",
              "       [1.1026859e-06, 3.3974648e-05],\n",
              "       [8.9406967e-08, 6.5814555e-03],\n",
              "       [1.1920929e-07, 3.9543563e-01],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 5.0663948e-07],\n",
              "       [1.1920929e-07, 1.6223907e-01],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [2.0861626e-07, 1.7051995e-03],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [3.8743019e-07, 3.3050776e-05],\n",
              "       [1.6093254e-06, 6.2806010e-03],\n",
              "       [8.9406967e-08, 8.7916851e-06],\n",
              "       [2.6822090e-07, 2.5272369e-05],\n",
              "       [0.0000000e+00, 1.1920929e-07],\n",
              "       [8.6426735e-07, 2.5564432e-04],\n",
              "       [8.9406967e-08, 1.2427568e-05],\n",
              "       [8.9406967e-08, 1.6301870e-05],\n",
              "       [2.6822090e-07, 2.0384789e-05],\n",
              "       [0.0000000e+00, 9.9848032e-01],\n",
              "       [1.4603138e-06, 1.4731020e-02],\n",
              "       [5.9604645e-08, 5.4031610e-05],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 9.9996233e-01],\n",
              "       [0.0000000e+00, 3.3676624e-06],\n",
              "       [0.0000000e+00, 2.9802322e-08],\n",
              "       [0.0000000e+00, 2.6822090e-07],\n",
              "       [0.0000000e+00, 6.0411245e-01],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 2.9802322e-08],\n",
              "       [0.0000000e+00, 9.9993205e-01],\n",
              "       [1.4901161e-06, 4.5275688e-04],\n",
              "       [5.9604645e-08, 2.3525184e-01],\n",
              "       [0.0000000e+00, 5.0663948e-07],\n",
              "       [5.9604645e-08, 6.5863132e-06],\n",
              "       [0.0000000e+00, 4.7683716e-07],\n",
              "       [0.0000000e+00, 2.6822090e-07],\n",
              "       [0.0000000e+00, 1.2557447e-02],\n",
              "       [1.1920929e-07, 1.1384487e-04],\n",
              "       [0.0000000e+00, 8.9406967e-08],\n",
              "       [2.9802322e-08, 1.2844801e-05],\n",
              "       [0.0000000e+00, 1.4901161e-07],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 1.0430813e-05],\n",
              "       [0.0000000e+00, 6.1542684e-01],\n",
              "       [3.2782555e-07, 4.8965216e-05],\n",
              "       [1.4901161e-07, 3.8743019e-06],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [1.1026859e-06, 1.4162064e-04],\n",
              "       [0.0000000e+00, 0.0000000e+00],\n",
              "       [5.9604645e-08, 1.4334917e-05],\n",
              "       [1.1920929e-07, 8.7803602e-04],\n",
              "       [1.1920929e-07, 9.9987888e-01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7ElCI1R7NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschrÃ¤nken. Jedoch soll **end-to-end** trainiert werden, hierfÃ¼r sollte vllt eine art Funktion eingesetzt werden, welche Ã¼ber die GAN's Layer zurÃ¼ck geht.\n",
        "Muss ich hierfÃ¼r die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klÃ¤ren: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3228b967-277f-4c93-b6c4-60b18f5356cb"
      },
      "source": [
        "\n",
        "\n",
        "def get_encoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True,kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False,kernel_initializer=randN_initial, activation=None))\n",
        "  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "  return model\n",
        "\n",
        "def get_decoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=True,kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True,kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=False,kernel_initializer=randN_initial, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "encoder = get_encoder()\n",
        "decoder = get_decoder()\n",
        "\n",
        "encoder.summary()\n",
        "generator.summary()\n",
        "decoder.summary()\n",
        "   \n",
        "def get_AE(encoder, generator, decoder):\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(encoder)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(decoder)\n",
        "  return AE_model\n",
        "          \n",
        "    \n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(1000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE(encoder, generator, decoder)\n",
        "AE.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = AE.fit(data, data, batch_size=200,steps_per_epoch=5000, epochs=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_47 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 2)                 32        \n",
            "_________________________________________________________________\n",
            "lambda_15 (Lambda)           (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 576\n",
            "Trainable params: 576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  160       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  64        \n",
            "=================================================================\n",
            "Total params: 1,280\n",
            "Trainable params: 1,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_50 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 16)                48        \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 16)                256       \n",
            "=================================================================\n",
            "Total params: 310\n",
            "Trainable params: 310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1000000, 16)\n",
            "(10000, 16)\n",
            "Train on 1000000 samples\n",
            "Epoch 1/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 1.6129 - accuracy: 0.4311\n",
            "Epoch 2/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.5124 - accuracy: 0.8338\n",
            "Epoch 3/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.2046 - accuracy: 0.9248\n",
            "Epoch 4/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0851 - accuracy: 0.9873\n",
            "Epoch 5/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0434 - accuracy: 0.9960\n",
            "Epoch 7/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0581 - accuracy: 0.9944\n",
            "Epoch 8/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0424 - accuracy: 0.9965\n",
            "Epoch 10/10\n",
            "1000000/1000000 [==============================] - 11s 11us/sample - loss: 0.0017 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB =8\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42fcfd39-39f6-4594-f5e3-7c920cdc7363"
      },
      "source": [
        "print(sum(diff_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(16,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "71ffe404-2304-4f86-fc63-714821b19a09"
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()\n",
        "print(M)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4e9bc196eecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtes_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcoding\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtes_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"b.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 715\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    716\u001b[0m     return predict_loop(\n\u001b[1;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2435\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_16 to have shape (16,) but got array with shape (4,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdAwT-5ynhI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "4719d628-72d6-4e3a-a670-99425f3d3498"
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= AE.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-45107cf9b16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtes_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcoding\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtes_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"b.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1819\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2036\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2038\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2039\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_predict_on_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 772\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer sequential_25 is incompatible with the layer: expected axis -1 of input shape to have value 16 but received input with shape [None, 4]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDfTMdthneHM",
        "colab_type": "text"
      },
      "source": [
        "## Trainingparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQ1bKE_nJSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_EbNodB = 6\n",
        "val_EbNodB = train_EbNodB\n",
        "\n",
        "training_params = [\n",
        "    #batch_size, lr, ebnodb, iterations\n",
        "    [100    , 0.001, train_EbNodB, 1000],\n",
        "    [100    , 0.0001, train_EbNodB, 10000],\n",
        "    [1000    , 0.0001, train_EbNodB, 10000]\n",
        "]\n",
        "\n",
        "validation_params = [\n",
        "    #batch_size, ebnodb, val_steps \n",
        "    [100000, val_EbNodB, 100],\n",
        "    [100000, val_EbNodB, 1000],\n",
        "    [100000, val_EbNodB, 1000]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLzQO7yQnP1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "b400ed7d-a38e-4091-921c-040a80067c91"
      },
      "source": [
        "model_file_baseline = 'models/ae_baseline_k_{}_n_{}'.format(k,n)\n",
        "\n",
        "ae_baseline = AE(k,n,useGAN=False,seed=seed)\n",
        "ae_baseline.train(training_params, validation_params)\n",
        "\n",
        "ae_baseline.save(model_file_baseline)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a3cfbfeb8464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_file_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models/ae_baseline_k_{}_n_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mae_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0museGAN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mae_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    850\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'useGAN'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}