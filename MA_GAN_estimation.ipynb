{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "20e66058-5547-4eda-a5be-694f10cf29ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-rc0\n",
        "!pip install -q pyyaml h5py\n",
        "#!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.0.0rc0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.1.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0a20190806)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.16.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - LÃ¤nge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 2       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "f7eea2fa-1212-48e3-e486-8b12239bba3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(input):\n",
        "  G_n = tf.random.normal([tf.shape(input)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "  inputs = tf.concat(values=[input, G_n], axis=1)\n",
        "  return inputs\n",
        "    \n",
        "def generator(x = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#, input_shape=(2*n,))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True,  activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "generator= generator()\n",
        "test = generator(x)\n",
        "print(test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.3847214  0.45205903]\n",
            " [0.40781444 0.51030904]\n",
            " [0.39136463 0.3186814 ]\n",
            " [0.48447654 0.44672066]\n",
            " [0.31635937 0.3096683 ]\n",
            " [0.48351362 0.45671377]\n",
            " [0.41978294 0.43458933]\n",
            " [0.5036941  0.35001564]\n",
            " [0.46928412 0.4781003 ]\n",
            " [0.48489335 0.46770343]\n",
            " [0.47284707 0.5145283 ]\n",
            " [0.35865396 0.39424273]\n",
            " [0.4141124  0.44461432]\n",
            " [0.4178626  0.43320912]\n",
            " [0.53217256 0.45222944]\n",
            " [0.48151407 0.5291374 ]\n",
            " [0.44885522 0.4723169 ]\n",
            " [0.4705143  0.45513204]\n",
            " [0.44168726 0.44260266]\n",
            " [0.37785655 0.39247933]\n",
            " [0.37949592 0.3826722 ]\n",
            " [0.43495333 0.45986387]\n",
            " [0.4871899  0.4691099 ]\n",
            " [0.28457725 0.32118815]\n",
            " [0.41484857 0.3612313 ]\n",
            " [0.40345716 0.4687501 ]\n",
            " [0.36532715 0.37204608]\n",
            " [0.49078798 0.43717402]\n",
            " [0.491386   0.45347074]\n",
            " [0.44835868 0.51403636]\n",
            " [0.35506868 0.3913205 ]\n",
            " [0.48198825 0.49104452]\n",
            " [0.47259298 0.46542475]\n",
            " [0.4805718  0.48501587]\n",
            " [0.39726013 0.4331367 ]\n",
            " [0.45337555 0.5048993 ]\n",
            " [0.45482498 0.34701037]\n",
            " [0.4245696  0.3813215 ]\n",
            " [0.4694346  0.4984609 ]\n",
            " [0.4714382  0.41532582]\n",
            " [0.46686465 0.48403972]\n",
            " [0.44431216 0.43545154]\n",
            " [0.41024527 0.45522228]\n",
            " [0.42722723 0.42487442]\n",
            " [0.28598514 0.3301829 ]\n",
            " [0.45003566 0.45673162]\n",
            " [0.41008085 0.39987564]\n",
            " [0.49261042 0.3998412 ]\n",
            " [0.47271404 0.4855789 ]\n",
            " [0.46063066 0.4583208 ]\n",
            " [0.48025933 0.431324  ]\n",
            " [0.3994597  0.51864135]\n",
            " [0.47093627 0.4659574 ]\n",
            " [0.44854504 0.44135216]\n",
            " [0.46035054 0.5049581 ]\n",
            " [0.43132252 0.3950525 ]\n",
            " [0.41628885 0.3810315 ]\n",
            " [0.40569532 0.38498682]\n",
            " [0.44421995 0.45949298]\n",
            " [0.47011298 0.4363994 ]\n",
            " [0.49683335 0.5359858 ]\n",
            " [0.4742111  0.4775542 ]\n",
            " [0.4585632  0.41113436]\n",
            " [0.42930046 0.46779472]\n",
            " [0.47821054 0.46505526]\n",
            " [0.36043113 0.37745148]\n",
            " [0.47760504 0.43284172]\n",
            " [0.4427327  0.47367507]\n",
            " [0.39911455 0.4183995 ]\n",
            " [0.48218408 0.42077774]\n",
            " [0.39378068 0.39628723]\n",
            " [0.47885513 0.42467973]\n",
            " [0.34264442 0.3446362 ]\n",
            " [0.36449176 0.45801088]\n",
            " [0.44948703 0.4634813 ]\n",
            " [0.4384375  0.31856462]\n",
            " [0.3483923  0.36222506]\n",
            " [0.3808211  0.37390244]\n",
            " [0.38967976 0.36705786]\n",
            " [0.429048   0.4312371 ]\n",
            " [0.4572062  0.5331714 ]\n",
            " [0.45745996 0.44026098]\n",
            " [0.47931907 0.46906132]\n",
            " [0.41154817 0.43335283]\n",
            " [0.48594996 0.45725816]\n",
            " [0.4852992  0.46273893]\n",
            " [0.43597376 0.41740668]\n",
            " [0.47028977 0.45918882]\n",
            " [0.41600984 0.4457975 ]\n",
            " [0.48503736 0.48741248]\n",
            " [0.4501798  0.39554098]\n",
            " [0.43965495 0.45217344]\n",
            " [0.47445562 0.45651078]\n",
            " [0.5125757  0.44323245]\n",
            " [0.4891248  0.45144957]\n",
            " [0.5322286  0.45458433]\n",
            " [0.4046707  0.37420675]\n",
            " [0.41560346 0.4011308 ]\n",
            " [0.48310834 0.43480963]\n",
            " [0.43536562 0.36252528]], shape=(100, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 6\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu',input_shape=((2*n,))))\n",
        "  model.add(tf.keras.layers.Dense(16,use_bias=True,  activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, Ã¼berhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "4b4c9bfb-f879-42a3-ec93-c85363796f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  \n",
        "fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=-1)\n",
        "\n",
        "print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "print(fake_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (100, 4)\n",
            "tf.Tensor(\n",
            "[[0.4494692 ]\n",
            " [0.4868168 ]\n",
            " [0.4785013 ]\n",
            " [0.47385728]\n",
            " [0.44673428]\n",
            " [0.47257677]\n",
            " [0.49035   ]\n",
            " [0.47400647]\n",
            " [0.47585833]\n",
            " [0.48369405]\n",
            " [0.49765432]\n",
            " [0.45803955]\n",
            " [0.45399636]\n",
            " [0.44641033]\n",
            " [0.46668154]\n",
            " [0.4701506 ]\n",
            " [0.48418742]\n",
            " [0.48134363]\n",
            " [0.48424035]\n",
            " [0.4813925 ]\n",
            " [0.48246455]\n",
            " [0.49877486]\n",
            " [0.48495856]\n",
            " [0.47199613]\n",
            " [0.4635908 ]\n",
            " [0.47382388]\n",
            " [0.47390765]\n",
            " [0.41667894]\n",
            " [0.4586736 ]\n",
            " [0.45911396]\n",
            " [0.48219657]\n",
            " [0.4413546 ]\n",
            " [0.46241146]\n",
            " [0.48892385]\n",
            " [0.41482207]\n",
            " [0.46186036]\n",
            " [0.4901976 ]\n",
            " [0.48122415]\n",
            " [0.46786976]\n",
            " [0.4569119 ]\n",
            " [0.44904873]\n",
            " [0.48547962]\n",
            " [0.42815655]\n",
            " [0.4971635 ]\n",
            " [0.47636583]\n",
            " [0.49247077]\n",
            " [0.4838431 ]\n",
            " [0.4785889 ]\n",
            " [0.4587316 ]\n",
            " [0.5012387 ]\n",
            " [0.4805761 ]\n",
            " [0.47624555]\n",
            " [0.49004227]\n",
            " [0.4953094 ]\n",
            " [0.40820998]\n",
            " [0.48335055]\n",
            " [0.45679608]\n",
            " [0.48628777]\n",
            " [0.46768808]\n",
            " [0.49288192]\n",
            " [0.48049268]\n",
            " [0.39941826]\n",
            " [0.45599502]\n",
            " [0.49705434]\n",
            " [0.49165142]\n",
            " [0.43796673]\n",
            " [0.4764639 ]\n",
            " [0.50152725]\n",
            " [0.47638842]\n",
            " [0.48159453]\n",
            " [0.44443244]\n",
            " [0.47697848]\n",
            " [0.44266984]\n",
            " [0.4831515 ]\n",
            " [0.46797565]\n",
            " [0.48134106]\n",
            " [0.4591276 ]\n",
            " [0.47214624]\n",
            " [0.49694455]\n",
            " [0.45141917]\n",
            " [0.47184494]\n",
            " [0.49148628]\n",
            " [0.42295682]\n",
            " [0.46338928]\n",
            " [0.3988203 ]\n",
            " [0.4846882 ]\n",
            " [0.45309865]\n",
            " [0.49997634]\n",
            " [0.47695643]\n",
            " [0.4763531 ]\n",
            " [0.49022225]\n",
            " [0.44333318]\n",
            " [0.46302593]\n",
            " [0.45342094]\n",
            " [0.47066373]\n",
            " [0.43009743]\n",
            " [0.44570816]\n",
            " [0.4582138 ]\n",
            " [0.48102233]\n",
            " [0.4615389 ]], shape=(100, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "  return loss\n",
        "  \n",
        "def generator_loss(fake_output, generator):\n",
        "  loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "  return loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=100):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator(x), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 2\n",
        "  \n",
        "  inputs_ = tf.concat(values=[inputs, inputs],  axis=-1)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=1)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=1)\n",
        "  inputs_hist = np.mean(inputs_,axis=1)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  \n",
        "  fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  plt.hist(fake_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoches = 50\n",
        "batch_size = 100\n",
        "\n",
        "evaluation_per_epochs = 100\n",
        "\n",
        "noise_dim = n        #noch Ã¤ndern wenn ich noise Ã¤ndere\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "    train_step(epoch, steps_per_epoches , batch_size, generator, discriminator) \n",
        "    if counter%5 == 0:\n",
        "      print(\"counter %d:\" % (counter))\n",
        "    if counter%5 == 0:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    real_c = real_channel(x)\n",
        "    fake_c = generator(x)\n",
        "    if tf.math.is_nan(fake_c[1,1]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "\n",
        "  print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        "    \n",
        "   \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "\n",
        "def train_step(epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "\n",
        "    \n",
        "  for j in range(steps_per_epoches):\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data, training=True)\n",
        "      fake_output = discriminator(fake_training_data, training=True)\n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #print(disc_loss, gen_loss)\n",
        "          \n",
        "    \n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      \n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "9bcc792b-a152-4cf9-cd3a-8632610311fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size, generator, discriminator)\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 35.13412070274353 sec,\n",
            "Time for epoch 2 is 20.629934310913086 sec,\n",
            "Time for epoch 3 is 20.19384241104126 sec,\n",
            "Time for epoch 4 is 20.12710213661194 sec,\n",
            "counter 5:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbWaWGAe3mVliHNxmZolxcJuZJeb/A1E+xcnRyRFaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 5 is 31.14104723930359 sec,\n",
            "Time for epoch 6 is 18.54293417930603 sec,\n",
            "Time for epoch 7 is 20.662286043167114 sec,\n",
            "Time for epoch 8 is 18.793423175811768 sec,\n",
            "Time for epoch 9 is 21.19813823699951 sec,\n",
            "counter 10:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  keep = (tmp_a >= first_edge)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
            "  keep &= (tmp_a <= last_edge)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhIYBbeISGAU3CIigflf049kj155zy4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHtVJREFUeJzt3XucFOWd7/HPD0RHAblLuIOJgspN\nHAgKKmiirETBVRONSXBPItHo0Rg9EXXPSqJJyJEEj2ZdQ6JHckRWozHeIxq5RCMq+ALlYsTLqAME\nBpTbIoaB3/5Rz4zN0D3dPdM9PTx+369Xv6a6q/qpXz1V/e2q6p5qc3dERGT/16LUBYiISGEo0EVE\nIqFAFxGJhAJdRCQSCnQRkUgo0EVEIqFAr8PMtpvZ4UWex3wz+04YvtDM5haw7RVmNiYMTzWzewvY\n9vVm9ttCtZfHfPub2VIz22ZmVzT1/OtjZveY2c2lrqNGqdbR/qrQr79SO6DUBTQ37t6miec3G5id\nbTozuweodPd/zdLeMYWoK7wp3OvuPVPa/mkh2m6AHwLz3H1oqO0ecuiL5sDMHDjC3d8qQttjaMJ1\nVMxlKZVcX3/7C+2hR8LMYn5z7gOsKFRjzamvmlMtEgF3j+4GVADXAK8BW4D7gbKU8RcDbwEfAo8C\n3VPGOfCFMHwGsBLYBqwBrkmZ7ivAUmAz8FdgcD31fBl4I9TyK2AB8J0w7iLg+TBswAxgA7AVeB0Y\nCEwGdgH/ALYDj6Us57VhOT8hOeKqAL4Uxk8FHgzLvw14FRiSblnD/XuAm4HWwMfAnjC/7UD30N69\nKdOfRRK0m4H5wFG5roM6/fN54DlgE7CRZI+pfRj3HLAb2BnqyNQX3YGHgCrgXeCKlPZr+uHe0K/f\nSVND2nWdun4ybCP3AHcCz4TnLgD6hHELw7T/FWr9GjAGqAzr7e/A/wc6AI+H2j8Kwz1T5tcR+H/A\n2jD+j7msI6BvmP8k4P3QtzektHswMCu0uYrkSKiynu04dbmnAg8AvwvLvQIor7P+rwt9+lGovyzH\nPs34ustQV02fXk3y2lkH/EvK+HahzirgPeBfgRa5vv7CuIOA6aEf14d1fnCps26fvih1AUVZqGRj\nejls4B3DxnpJGHdK2LCHhZV0O7Aww4a1DjgxDHcAhoXhY8NK/yLQMrxgKoCD0tTSOWyY5wKtgKuA\natIH+unAEqB92LiOArqFcfcAN6dZzqVAr5qNi30DfVfKvK8hCbtWdZe17jxqXiR15jeVT8PiSJKg\n+nJo+4ckb5IHZlsHafroC6Gdg4AuJEF4a8r4+aSEcN2+IDnSXAL8G3AgcDjwDnB6nX6YGKbd54VY\nz7quXT8ZtpF7wvo9KdT/f1OnT9PHY8L6/3mY/mCgE3AOcAjQFvg98MeU5zxB8obYIfT1yTmuo75h\n/r8J8xlC8sZ/VBg/jeQNqAPQk+TNN59A30kSvi2BnwGL6myby0m2zY7AC3y6bWXr07Trop66avr0\nx6F/zgB2AB3C+N8Bj4S+7Qu8CXw7z9ffDJKdv46hnceAn5U66+reYj7lcpu7r3X3D0k6f2h4/ELg\nbnd/1d0/IdmLON7M+qZpYxdwtJkd6u4fufur4fHJwK/d/SV33+3us0heKCPTtHEGsMLdH3T3XcCt\nJHtm6ewi2VgGAObuq9x9XQ7L+YG7f5xh/JKUef8SKMtQZ76+Bjzh7s+EtqeThMYJdWpLtw724u5v\nhXY+cfeqUOfJedQyHOji7j9293+4+zskIXZ+yjQvuvsf3X1Phr7KtK5z8YS7Lwzb0w0k21Oveqbf\nA9wYlvdjd9/k7g+5+w533wb8hLD8ZtYN+CeSN8OP3H2Xuy/IozaAH4X5LAOWkQQ7wFeBn4Z2K4Hb\n8mz3eXd/0t13kxxpDKkz/ldh2/wwLNMFObbbkHWxC/hx6J8nSY5Y+ptZS5Lt4Dp33+buFcAvgG9m\naGOf15+ZGclr/ip3/zCso5+y9/bVLMQc6KmhuQOo+bCzO8lhFwDuvp3kUL9HmjbOIQnk98xsgZkd\nHx7vA1xtZptrbiR7It3TtNEd+CBlfp56P5W7P0dySubfgQ1mNtPMDs2ynGnbSjfe3feQHJqmqzNf\ndftxT5hXaj9mWgd7MbOuZvafZrbGzLaSnBrpnEctfYDuddbH9UDXlGmy9VOmdZ2L1D7eTnIqr74+\nrnL3nTV3zOwQM/u1mb0Xln8h0D6EUS/gQ3f/KI966qrvtZDaL9n6KFu7ZXU+E0ht7z1y3+4asi42\nuXt1nXrakGxHrUjZVsPwPq/3el5/XUiOnpakbF9/Co83KzEHeiZrSQIAADNrTXLIu6buhO7+irtP\nAA4jOW/5QBj1AfATd2+fcjvE3eekmd86khdlzfws9X6aed7m7scBR5Oc1vhfNaMyPSVTW0HqvFuQ\nHFqvDQ/tINlQa3wuj3br9mPNcu3Tjzn4aZjfIHc/FPgGySFvJnVr+wB4t876aOvuZ9TznL0bzLyu\n/4uUPjKzz6V5emoftyE5LF+bZrpMtVwN9Ae+GJb/pJrmwrJ1NLP2ObSTr3Uk20ON+o4qGiK1vd58\n2if19mk966IhNpLsefdJeaw3GbbTDK+/jSSfVxyTsn218yb+RlwuPouBPgf4FzMbamYHkYTJS+FQ\nrJaZHRi+o9ounFLYSnKoDMnh/CVm9kVLtDaz8WbWNs38ngCOMbN/DnsvV7B3cKbOc3hosxXJRr8z\nZZ7rSc4N5+u4lHl/n+TU0KIwbinwdTNraWbj2Ps0x3qgk5m1y9DuA8B4Mzs11Ht1aPuvDaixLckh\n8hYz68Gnb2KZ1O2Ll4FtZnatmR0clmegmQ3PZeZZ1vUykvU31MzKSM4d13WGmY02swOBm0jOJdfs\nneay3tqSBMZmM+sI3FgzIpxyewq4w8w6mFkrM6sJ/GzrKJsHgOtCuz2AyxvYTiaXmVnPsEw3kHwO\nAPX0aZZ1kbdwOugB4Cdm1tbM+gA/IDkK3Eum1184+vwNMMPMDgvT9jCz0xtaV7F85gLd3Z8F/jfJ\nNyLWkXzDItO5sG8CFeEw+BKS8++4+2KSb8r8iuQT/LdIPlxJN7+NwHkkH0BtAo4g+YAonUNJNpyP\nSA4LNwG3hHF3kZxX3Gxmf8xtaYHkw6CvhTa/CfxzeKEAXAmcSfItlQtJ9oZq6n6D5M3vnTDPvQ6X\n3f1vJHvSt5PswZwJnOnu/8ijtho/IvmQegvJG+Afsky/V1+EF+1XSM7Rvxvq+S3JtxtylWldv0ny\nYduzwGrg+TTPvY8khD8EjiPplxpTgVmh1q9mmPetJJ8/bCR5s/1Tmtp2kXxTagPJG3PWdZSDH5Oc\ngns3LN+DJG/KhXIfMJfkA+q3Sb5BlUufpl0XjfA/SQL6nTCv+4C700xX3+vvWpLX+aJQ17MkR1XN\niiWndEXks87MLgXOd/d8PpDO1FYFyTeTnm10YZKzz9weuogkzKybmY0ysxZm1p/ktNnDpa5LGk6B\nLvLZdSDwa5Lv0T9HcnrujpJWlIEl16jZnub2VKlra050ykVEJBLaQxcRiUSTXhioc+fO3rdv36ac\npYjIfm/JkiUb3T3rPzI1aaD37duXxYsXN+UsRUT2e2b2XvapdMpFRCQaCnQRkUgo0EVEIqFfSxGR\nBtu1axeVlZXs3Lkz+8SSVVlZGT179qRVq1YNer4CXUQarLKykrZt29K3b1+SC25KQ7k7mzZtorKy\nkn79+jWoDZ1yEZEG27lzJ506dVKYF4CZ0alTp0Yd7WQNdDPrZWbzzGylma0wsyvD41Mt+UGCpeF2\nRra2RCQ+CvPCaWxf5nLKpRq42t1fDdf7XmJmz4RxM9x9eqMqEBGRgsga6OEC++vC8DYzW0X6n2sT\nkc+4UdOeY83mTD9vm78e7Q/mhSmnFKy9Yrr11luZPHkyhxxySPaJiySvD0Ut+SHlY4GXgFHA5Wb2\nLWAxyV78Pr97aGaTSX5gld69ezeyXJHiSA2i/SlEmps1mz+mYtr4grXXd8oTBWursdwdd6dFi/Rn\nqm+99Va+8Y1v5BXou3fvpmXLloUqMfcPRcNvJT4EfN/dtwL/QfJrP0NJ9uB/ke557j7T3cvdvbxL\nl2b3m6oiwKdBVDFtfEH3MKX4brrpJvr378/o0aO54IILmD59Om+//Tbjxo3juOOO48QTT+SNN94A\n4KKLLuKKK67ghBNO4PDDD+fBBx+sbeeWW25h+PDhDB48mBtvTH4FsKKigv79+/Otb32LgQMH8sEH\nH3DppZdSXl7OMcccUzvdbbfdxtq1axk7dixjx44FYM6cOQwaNIiBAwdy7bXX1s6nTZs2XH311QwZ\nMoQXX3yxsJ1R865T343kV7OfBn6QYXxfYHm2do477jgXaY76XPt42mGp38qVK/e6X+i+y9beyy+/\n7EOGDPGPP/7Yt27d6l/4whf8lltu8VNOOcXffPNNd3dftGiRjx071t3dJ02a5Oeee67v3r3bV6xY\n4Z///Ofd3f3pp5/2iy++2Pfs2eO7d+/28ePH+4IFC/zdd991M/MXX3yxdp6bNm1yd/fq6mo/+eST\nfdmyZUmtffp4VVWVu7uvWbPGe/Xq5Rs2bPBdu3b52LFj/eGHH3Z3d8Dvv//+jMtUt0/DcxZ7Dlmd\n9ZRL+DX3u4BV7v7LlMe7eXJ+HeBsYHkh32hERLJ54YUXmDBhAmVlZZSVlXHmmWeyc+dO/vrXv3Le\neefVTvfJJ5/+VOrEiRNp0aIFRx99NOvXrwdg7ty5zJ07l2OPPRaA7du3s3r1anr37k2fPn0YOXJk\n7fMfeOABZs6cSXV1NevWrWPlypUMHjx4r7peeeUVxowZQ81ZiQsvvJCFCxcyceJEWrZsyTnnnFOU\n/sjlHPookh9tfd3MlobHrgcuMLOhgAMVwHeLUqGISB727NlD+/btWbp0adrxBx10UO2whx/4cXeu\nu+46vvvdvWOsoqKC1q1b195/9913mT59Oq+88godOnTgoosuyvt742VlZQU9b54q6zl0d3/e3c3d\nB7v70HB70t2/6e6DwuNnpeyti4g0iVGjRvHYY4+xc+dOtm/fzuOPP84hhxxCv379+P3vfw8kYb1s\n2bJ62zn99NO5++672b59OwBr1qxhw4YN+0y3detWWrduTbt27Vi/fj1PPfXpL+C1bduWbdu2ATBi\nxAgWLFjAxo0b2b17N3PmzOHkkxv929tZ6V//RaRgerQ/uKDfTOnR/uB6xw8fPpyzzjqLwYMH07Vr\nVwYNGkS7du2YPXs2l156KTfffDO7du3i/PPPZ8iQIRnbOe2001i1ahXHH388kHxwee+99+6zJz1k\nyBCOPfZYBgwYQK9evRg1alTtuMmTJzNu3Di6d+/OvHnzmDZtGmPHjsXdGT9+PBMmTGhET+SmSX9T\ntLy83PUDF9Ic9Z3yRO3X7VKHpX6rVq3iqKOOKmkN27dvp02bNuzYsYOTTjqJmTNnMmzYsJLW1Bjp\n+tTMlrh7ebbnag9dRPZrkydPZuXKlezcuZNJkybt12HeWAp0Edmv3XfffaUuodnQ1RZFRCKhQBcR\niYQCXUQkEgp0EZFI6ENRESmcGYNgy/uFa69db7jq9YyjN2/ezH333cf3vve9ws0zjfnz53PggQdy\nwgknFHU+jaVAF5HC2fI+TN1SuPamtqt39ObNm7njjjtyDvSai1hlugRuJvPnz6dNmzbNPtB1ykVE\n9ltTpkzh7bffZujQoVx11VWceuqpDBs2jEGDBvHII48A6S+Be9ddd3HkkUcyYsQILr74Yi6//HIA\nqqqqOOeccxg+fDjDhw/nhRdeoKKigjvvvJMZM2YwdOhQ/vKXv5RykeulPXQR2W9NmzaN5cuXs3Tp\nUqqrq9mxYweHHnooGzduZOTIkZx11lkArF69mlmzZjFy5EjWrl3LTTfdxKuvvkrbtm055ZRTai8L\ncOWVV3LVVVcxevRo3n//fU4//XRWrVrFJZdcQps2bbjmmmtKubhZKdBFJAruzvXXX8/ChQtp0aIF\na9asqb08buolcF9++WVOPvlkOnbsCMB5553Hm2++CcCzzz7LypUra9vcunVr7QW79gcKdBGJwuzZ\ns6mqqmLJkiW0atWKvn371l7aNvUSuPXZs2cPixYtoqysrJilFo3OoYvIfiv1krVbtmzhsMMOo1Wr\nVsybN4/33nsv7XOGDx/OggUL+Oijj6iuruahhx6qHXfaaadx++23196vuaZ66nyaM+2hi0jhtOud\n9ZspebdXj06dOjFq1CgGDhzI8OHDeeONNxg0aBDl5eUMGDAg7XN69OjB9ddfz4gRI+jYsSMDBgyg\nXbuk5ttuu43LLruMwYMHU11dzUknncSdd97JmWeeybnnnssjjzzC7bffzoknnli4ZSwgBbqIFE49\n3xkvllwuzrV8+d6/kPn1r3+dyZMnU11dzdlnn83EiRMB6Ny5M/fff/8+zz/yyCN57bXXClNwEemU\ni4h85kydOpWhQ4cycOBA+vXrVxvo+zvtoYvIZ8706dNLXUJRaA9dRBqlKX/1LHaN7UsFuog0WFlZ\nGZs2bVKoF4C7s2nTpkZ9ZVKnXESkwXr27EllZSVVVVWlLiUKZWVl9OzZs8HPV6CLSIO1atWKfv36\nlboMCXTKRUQkEgp0EZFIKNBFRCKhQBcRiYQCXUQkEgp0EZFIKNBFRCKhQBcRiYQCXUQkElkD3cx6\nmdk8M1tpZivM7MrweEcze8bMVoe/HYpfroiIZJLLHno1cLW7Hw2MBC4zs6OBKcCf3f0I4M/hvoiI\nlEjWQHf3de7+ahjeBqwCegATgFlhsllAHFeIFxHZT+V1Dt3M+gLHAi8BXd19XRj1d6BrhudMNrPF\nZrZYV2QTESmenAPdzNoADwHfd/etqeM8uRhy2gsiu/tMdy939/IuXbo0qlgREcksp0A3s1YkYT7b\n3f8QHl5vZt3C+G7AhuKUKCIiucjlWy4G3AWscvdfpox6FJgUhicBjxS+PBERyVUuP3AxCvgm8LqZ\nLQ2PXQ9MAx4ws28D7wFfLU6JIiKSi6yB7u7PA5Zh9KmFLUdERBpK/ykqIhIJBbqISCQU6CIikVCg\ni4hEQoEuIhIJBbqISCQU6CIikVCgi4hEIpf/FBWJ3vMHXQFTvx6GOwPjS1uQSAMo0EWAnrYRpm5J\nhqe2K3E1Ig2jUy4iIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQ\noIuIREKBLiISCQW6iEgkFOgiIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQoIuIREKBLiISCQW6iEgk\nFOgiIpFQoIuIRCJroJvZ3Wa2wcyWpzw21czWmNnScDujuGWKiEg2ueyh3wOMS/P4DHcfGm5PFrYs\nERHJV9ZAd/eFwIdNUIuIiDRCY86hX25mr4VTMh0KVpGIiDRIQwP9P4DPA0OBdcAvMk1oZpPNbLGZ\nLa6qqmrg7EREJJsGBbq7r3f33e6+B/gNMKKeaWe6e7m7l3fp0qWhdYqISBYNCnQz65Zy92xgeaZp\nRUSkaRyQbQIzmwOMATqbWSVwIzDGzIYCDlQA3y1ijSIikoOsge7uF6R5+K4i1CIiIo2g/xQVEYmE\nAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQi\noUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGR\nSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYlE1kA3\ns7vNbIOZLU95rKOZPWNmq8PfDsUtU0REssllD/0eYFydx6YAf3b3I4A/h/siIlJCWQPd3RcCH9Z5\neAIwKwzPAiYWuC4REclTQ8+hd3X3dWH470DXTBOa2WQzW2xmi6uqqho4OxERyabRH4q6uwNez/iZ\n7l7u7uVdunRp7OxERCSDhgb6ejPrBhD+bihcSSIi0hANDfRHgUlheBLwSGHKERGRhsrla4tzgBeB\n/mZWaWbfBqYBXzaz1cCXwn0RESmhA7JN4O4XZBh1aoFrERGRRtB/ioqIREKBLiISCQW6iEgkFOgi\nIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQoIuIREKBLiISCQW6\niEgkFOgiIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQoIuIREKBLiISCQW6iEgkFOgiIpFQoIuIROKA\nUhcgUjIzBsGW9wGo9M70LHE5Io2lQJfPri3vw9QtAIye8gQVpa1GpNF0ykVEJBIKdBGRSCjQRUQi\noUAXEYmEAl1EJBKN+paLmVUA24DdQLW7lxeiKBERyV8hvrY41t03FqAdERFpBJ1yERGJRGMD3YG5\nZrbEzCanm8DMJpvZYjNbXFVV1cjZiYhIJo0N9NHuPgz4J+AyMzup7gTuPtPdy929vEuXLo2cnYiI\nZNKoQHf3NeHvBuBhYEQhihIRkfw1ONDNrLWZta0ZBk4DlheqMBERyU9jvuXSFXjYzGrauc/d/1SQ\nqkREJG8NDnR3fwcYUsBaRESkEfS1RRGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmE\nAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQi\noUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGR\nSCjQRUQioUAXEYmEAl1EJBIKdBGRSDQq0M1snJn9zczeMrMphSpKRETyd0BDn2hmLYF/B74MVAKv\nmNmj7r6yUMWJFNyMQbDl/WS4Xe/S1iJSYA0OdGAE8Ja7vwNgZv8JTAAU6NJ8bXkfpm6pd5JK70zP\nqe2SO+16w1WvN0FhIo3XmEDvAXyQcr8S+GLdicxsMjA53N1uZn9r4Pw6Axsb+NxiUl35KX1dP7J0\nj3a2n6erazn8IO30TaX0/ZWe6spfY2rrk8tEjQn0nLj7TGBmY9sxs8XuXl6AkgpKdeVHdeVHdeWn\nudYFTVNbYz4UXQP0SrnfMzwmIiIl0JhAfwU4wsz6mdmBwPnAo4UpS0RE8tXgUy7uXm1mlwNPAy2B\nu919RcEq21ejT9sUierKj+rKj+rKT3OtC5qgNnP3Ys9DRESagP5TVEQkEgp0EZFINNtAN7NbzOwN\nM3vNzB42s/YZpmvSyw+Y2XlmtsLM9phZxq8gmVmFmb1uZkvNbHEzqqup+6ujmT1jZqvD3w4Zptsd\n+mqpmRXtw/Vsy29mB5nZ/WH8S2bWt1i15FnXRWZWldJH32miuu42sw1mtjzDeDOz20Ldr5nZsGZS\n1xgz25LSX//WBDX1MrN5ZrYyvBavTDNNcfvL3ZvlDTgNOCAM/xz4eZppWgJvA4cDBwLLgKOLXNdR\nQH9gPlBez3QVQOcm7K+sdZWov/4PMCUMT0m3HsO47U3QR1mXH/gecGcYPh+4v5nUdRHwq6banlLm\nexIwDFieYfwZwFOAASOBl5pJXWOAx5u4r7oBw8JwW+DNNOuxqP3VbPfQ3X2uu1eHu4tIvudeV+3l\nB9z9H0DN5QeKWdcqd2/of7sWTY51NXl/hfZnheFZwMQiz68+uSx/ar0PAqeaWbH/VbQU6yUn7r4Q\n+LCeSSYAv/PEIqC9mXVrBnU1OXdf5+6vhuFtwCqS/6hPVdT+araBXsf/IHlXqyvd5QfqdmCpODDX\nzJaEyx80B6Xor67uvi4M/x3ommG6MjNbbGaLzKxYoZ/L8tdOE3YotgCdilRPPnUBnBMO0x80s15p\nxpdCc34NHm9my8zsKTM7pilnHE7VHQu8VGdUUfur6P/6Xx8zexb4XJpRN7j7I2GaG4BqYHZzqisH\no919jZkdBjxjZm+EvYpS11Vw9dWVesfd3cwyfU+2T+ivw4HnzOx1d3+70LXuxx4D5rj7J2b2XZKj\niFNKXFNz9irJNrXdzM4A/ggc0RQzNrM2wEPA9919a1PMs0ZJA93dv1TfeDO7CPgKcKqHE1B1FOXy\nA9nqyrGNNeHvBjN7mOSwulGBXoC6mry/zGy9mXVz93Xh0HJDhjZq+usdM5tPsndT6EDPZflrpqk0\nswOAdsCmAteRd13unlrDb0k+m2gOmuUlQFKD1N2fNLM7zKyzuxf1wl1m1ookzGe7+x/STFLU/mq2\np1zMbBzwQ+Asd9+RYbJmefkBM2ttZm1rhkk+4E37aXwTK0V/PQpMCsOTgH2OJMysg5kdFIY7A6Mo\nzmWYc1n+1HrPBZ7LsDPRpHXVOc96Fsn52ebgUeBb4dsbI4EtKafYSsbMPlfz2YeZjSDJuqK+MYf5\n3QWscvdfZpisuP3VlJ8C5/mJ8Vsk55qWhlvNNw+6A0/W+dT4TZK9uRuaoK6zSc57fQKsB56uWxfJ\ntxWWhduK5lJXifqrE/BnYDXwLNAxPF4O/DYMnwC8HvrrdeDbRaxnn+UHfkyy4wBQBvw+bH8vA4cX\nu49yrOtnYVtaBswDBjRRXXOAdcCusH19G7gEuCSMN5Ifunk7rLuM3/xq4rouT+mvRcAJTVDTaJLP\nzl5Lya0zmrK/9K//IiKRaLanXEREJD8KdBGRSCjQRUQioUAXEYmEAl1EJBIKdBGRSCjQRUQi8d8k\nKAt9IB6LzAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 10 is 29.73431134223938 sec,\n",
            "doesn't train the generator as expacted\n",
            "Time for the training is 29.739442825317383 sec,\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  160       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  64        \n",
            "=================================================================\n",
            "Total params: 1,280\n",
            "Trainable params: 1,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 704\n",
            "Trainable params: 704\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 3min 52s, sys: 5.32 s, total: 3min 58s\n",
            "Wall time: 3min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKRrixvwnA_m",
        "colab_type": "text"
      },
      "source": [
        "### Restore the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esovpz32jW6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#discriminator = keras.models.load_model('my_discriminator.h5')\n",
        "#generator = keras.models.load_model('my_generator.h5')\n",
        "#generator1 = generator(x)\n",
        "#generator1.fit(x, real_channel(x),  epochs = 10,\n",
        "#          validation_data = (x,real_channel(x)),\n",
        "#          callbacks = [cp_callback])\n",
        "\n",
        "#real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "#test_eval(real_eval_data, fake_eval_data, inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "outputId": "ff917b81-5fba-4d3e-b6d0-4440a4c5c942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator(x)\n",
        "\n",
        "if tf.math.is_nan(fake_c[1,1]) == True:\n",
        "  print(\"wrong\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wrong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschrÃ¤nken. Jedoch soll **end-to-end** trainiert werden, hierfÃ¼r sollte vllt eine art Funktion eingesetzt werden, welche Ã¼ber die GAN's Layer zurÃ¼ck geht.\n",
        "Muss ich hierfÃ¼r die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klÃ¤ren: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "0f78eaa8-400d-49e9-e0e8-c7ae0c15017d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "def get_encoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "  return model\n",
        "\n",
        "def get_decoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "encoder = get_encoder()\n",
        "decoder = get_decoder()\n",
        "\n",
        "encoder.summary()\n",
        "generator.summary()\n",
        "decoder.summary()\n",
        "   \n",
        "def get_AE(encoder, generator, decoder):\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(encoder)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(decoder)\n",
        "  return AE_model\n",
        "          \n",
        "    \n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(1000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE(encoder, generator, decoder)\n",
        "AE.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = AE.fit(data, data, batch_size=100,steps_per_epoch=1100, epochs=5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 32        \n",
            "_________________________________________________________________\n",
            "lambda_3 (Lambda)            (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 576\n",
            "Trainable params: 576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  160       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1056      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  64        \n",
            "=================================================================\n",
            "Total params: 1,280\n",
            "Trainable params: 1,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 16)                48        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 16)                256       \n",
            "=================================================================\n",
            "Total params: 310\n",
            "Trainable params: 310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1000000, 16)\n",
            "(10000, 16)\n",
            "Train on 1000000 samples\n",
            "Epoch 1/5\n",
            " 108300/1000000 [==>...........................] - ETA: 22s - loss: nan - accuracy: 0.0617Epoch 2/5\n",
            " 109900/1000000 [==>...........................] - ETA: 16s - loss: nan - accuracy: 0.0621Epoch 3/5\n",
            " 108600/1000000 [==>...........................] - ETA: 16s - loss: nan - accuracy: 0.0620Epoch 4/5\n",
            " 107900/1000000 [==>...........................] - ETA: 16s - loss: nan - accuracy: 0.0617Epoch 5/5\n",
            " 108700/1000000 [==>...........................] - ETA: 16s - loss: nan - accuracy: 0.0640"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 6\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sum(diff_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDfTMdthneHM",
        "colab_type": "text"
      },
      "source": [
        "## Trainingparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQ1bKE_nJSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_EbNodB = 6\n",
        "val_EbNodB = train_EbNodB\n",
        "\n",
        "training_params = [\n",
        "    #batch_size, lr, ebnodb, iterations\n",
        "    [100    , 0.001, train_EbNodB, 1000],\n",
        "    [100    , 0.0001, train_EbNodB, 10000],\n",
        "    [1000    , 0.0001, train_EbNodB, 10000]\n",
        "]\n",
        "\n",
        "validation_params = [\n",
        "    #batch_size, ebnodb, val_steps \n",
        "    [100000, val_EbNodB, 100],\n",
        "    [100000, val_EbNodB, 1000],\n",
        "    [100000, val_EbNodB, 1000]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLzQO7yQnP1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_baseline = 'models/ae_baseline_k_{}_n_{}'.format(k,n)\n",
        "\n",
        "ae_baseline = AE(k,n,useGAN=False,seed=seed)\n",
        "ae_baseline.train(training_params, validation_params)\n",
        "\n",
        "ae_baseline.save(model_file_baseline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}