{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "dfdec540-47e6-499b-b94a-99286041fd50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0rc2\n",
        "#!pip install -q pyyaml h5py\n",
        "#!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/b2/0a8f6f62cdd91c7d727efc717f339265ace99b36847f2bda7a9f2897cfee/tensorflow-2.0.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.8.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow==2.0.0rc2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (3.1.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow==2.0.0rc2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.16.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.33.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.11.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0rc2) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0rc2) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0rc2) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0rc2) (2.8.0)\n",
            "Installing collected packages: tensorboard, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0rc3\n",
            "    Uninstalling tensorflow-1.15.0rc3:\n",
            "      Successfully uninstalled tensorflow-1.15.0rc3\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-2.0.0rc2 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - Länge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 2       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 4      # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "def make_zero(x):\n",
        "  return tf.keras.backend.zeros(shape=x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))\n",
        "  \n",
        "  \n",
        "  \n",
        "train_SNR_dB = 7\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "#zero_initial = tf.keras.initializers.Zeros()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "00d60435-fa2b-4955-d5d5-6f2fb819ed14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "#\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(x):\n",
        "  G_n = tf.random.normal([tf.shape(x)[0],n])  #create noise directly within the generator  \n",
        "  return G_n\n",
        "    \n",
        "tf.print(generator_noise(x).shape)\n",
        "\n",
        "#def get_generator(input = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#,input_shape=((2*n,))))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "#  return model\n",
        "\n",
        "\n",
        "#input1 = tf.keras.layers.Input(shape=(n,))\n",
        "#x1 = tf.keras.layers.Dense(n, activation='relu')(input1)\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "#subtracted = tf.keras.layers.Concatenate(-1)([x1, x2])\n",
        "#h1 = tf.keras.layers.Dense(32)(subtracted)\n",
        "#h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "#out = tf.keras.layers.Dense(n, use_bias= False, activation='relu')(h2)\n",
        "\n",
        "#tf.reshape(input,(tf.shape(input)[0],-1))\n",
        "input1 = tf.keras.layers.Input(shape=(n,))\n",
        "x1 = tf.keras.layers.Dense(n)(input1)\n",
        "input2 =tf.random.normal([tf.shape(input1)[0],n]) \n",
        "x2 = tf.keras.layers.Dense(n)(input2)\n",
        "subtracted = tf.keras.layers.Concatenate(1)([x1, x2])\n",
        "h1 = tf.keras.layers.Dense(32,use_bias=True,  activation='relu')(subtracted)\n",
        "h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "out = tf.keras.layers.Dense(n, use_bias= True, activation='linear')(h2)\n",
        "\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#generator = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n",
        "generator = tf.keras.models.Model(inputs=[input1], outputs=out)\n",
        "generator.summary()\n",
        "#print(x.shape,(generator_noise(x)).shape)\n",
        "tf.print(generator([x]).shape)\n",
        "#test = generator(x)\n",
        "#print(test[1])\n",
        "generator.input\n",
        "#model.input"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "outputId": "c7bdb620-f357-4de4-96b5-c68f42633a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial,activation='relu',input_shape=((2*n,))))\n",
        "  #model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "discriminator.summary()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, überhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "9a4ea546-0262-4eb1-9eb3-9fb356e4d1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=-1)  \n",
        "fake_training_data = tf.concat(values=[generator([x]),x], axis=-1)# training =True),x], axis=-1)\n",
        "\n",
        "tf.print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "tf.print(fake_output)\n",
        "tf.print(real_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 8]) TensorShape([1000, 8])\n",
            "[[0.514648199]\n",
            " [0.508478403]\n",
            " [0.513381064]\n",
            " ...\n",
            " [0.491200328]\n",
            " [0.501303673]\n",
            " [0.499335855]]\n",
            "[[0.521009684]\n",
            " [0.526445]\n",
            " [0.528408]\n",
            " ...\n",
            " [0.504484057]\n",
            " [0.513618827]\n",
            " [0.514133334]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def discriminator_loss(real_output, fake_output):\n",
        "  #loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#  loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #Wasserstein GAN\n",
        "#  return loss\n",
        "\n",
        "def generator_loss(fake_output, generator):\n",
        "  return -tf.reduce_mean(fake_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCZBgwYBNYW",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8J9r3UpBNl1",
        "colab_type": "code",
        "outputId": "c6bc300d-f438-4011-a148-069675105a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "gen_loss =  -tf.reduce_mean(fake_output)\n",
        "#disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        "tf.print(disc_loss, gen_loss)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00706374645 -0.518188655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=1000):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator([x]), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 3\n",
        "  \n",
        "  #inputs_ = tf.concat(values=[inputs, inputs],  axis=0)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=0)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=0)\n",
        "  inputs_hist = np.mean(inputs,axis=0)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  tf.print(inputs_hist.shape)\n",
        "  \n",
        "  #fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  #real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  #plt.hist(fake_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  #plt.hist(real_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  #plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  #plt.legend([\"generator\", \"target\"])\n",
        "  #plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2000\n",
        "steps_per_epoches = 100\n",
        "batch_size = 1000\n",
        "\n",
        "evaluation_per_epochs = 10\n",
        "\n",
        "seed = tf.random.normal([batch_size, n])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUTZng_fFBk",
        "colab_type": "text"
      },
      "source": [
        "# Wasserstein clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFEdt29fEj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clip_D = [p.assign(tf.clip_by_value(p, -0.001, 0.001)) for p in discriminator.trainable_variables]\n",
        "\n",
        "#def get_disc_grad(trainable_variables):\n",
        "#  return [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in trainable_variables]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "\n",
        "    \n",
        "    train_step() \n",
        "    #tf.print(generator_optimizer.apply_gradients())\n",
        "    #if counter%5 == 0:\n",
        "    if counter%100==0:\n",
        "      tf.print(\"counter %d:\" % (counter))\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      tf.print(fake_c[0])\n",
        "    if counter%6 == 0 and counter<8:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    if counter%1000 == 0:\n",
        "      real_c = real_channel(x)\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "      #tf.print(fake_c[0])\n",
        "      tf.print(disc_loss, gen_loss)\n",
        "    #print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "      tf.print ('Time for epoch {},'.format(epoch + 1))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    fake_c = generator(x)\n",
        "    if tf.math.is_nan(fake_c[0,0]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message generator',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        " # print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(): #epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  for i in range(5):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "      fake_training_data = tf.concat(values=[generator(x),x], axis=1)# training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data)#, training=True)\n",
        "      fake_output = discriminator(fake_training_data)\n",
        "      \n",
        "      \n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(real_training_data.shape, real_output[1].shape)\n",
        "      #tf.debugging.check_numerics(disc_loss,'loss generator',name=None)\n",
        "      # clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in gradients_of_discriminator]   \n",
        "      #tf.print(real_training_data[0])\n",
        "      \n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(disc_loss, gen_loss)\n",
        "      if tf.math.is_nan(disc_loss) == False:\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "      if i == 4:  \n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "4bdada62-e12f-4bbd-a94c-d9853ced441e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size)\n",
        "print(generator(x)[1])\n",
        "generator.summary()\n",
        "discriminator.summary()\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG0FJREFUeJzt3XuUVOWd7vHvA0EbBZsIJFFuTeKF\nUW7KJSheACdKJIoZdeIliWTO2Gp0eTl6RnTmRCYmMz2jKxo0juFEV/SIRKNGMerSuLyjRC4LFcEo\nxla65UiDNhcFh4bf+aM2bdF009Xd1V1du5/PWrVSu/Zb7/7tavPU5t273q2IwMzM0qVboQswM7P8\nc7ibmaWQw93MLIUc7mZmKeRwNzNLIYe7mVkKOdyt4CRtlvT1dt7Gc5L+MXl+rqSn8tj3m5ImJc9n\nSbonj31fK+k3+erPuo4vFboAs4jo1cHbmwvMba6dpN8CVRHxL830d3g+6kq+IO6JiIFZff9bPvq2\nrsdH7matJMkHR9ZpOdwtLyRVSrpK0uuSNki6T1JJ1vrzJa2S9LGk+ZIOzFoXkg5Knp8saYWkTZKq\nJV2V1e47kpZJqpX0sqSRe6jnW5LeSmq5FVDWuhmSXkqeS9JNktZK2ijpDUnDJZUD5wL/lAwbPZq1\nn1dLeh34VNKXktf+NmvzJcn+b5K0VNKoxvY1Wf6tpJ9J2hd4Ajgw2d5mSQc2HOaRdGoyDFSbDDX9\nTa5/A+taHO6WT38PTAWGAiOBGQCSpgD/nqw/AHgf+F0TfdwBXBARvYHhwDNJH0cAdwIXAH2BXwPz\nJe3dsANJ/YCHgH8B+gHvAhOb2N6JwHHAIUBpUuP6iJhDZujmPyOiV0SckvWes4FpQJ+IqGukz+nA\n74H9gXuBhyX1aGL7AETEp8C3gQ+T7fWKiA8b7NchwDzgcqA/8DjwqKS9spo1+jewrsfhbvk0OyI+\njIiPgUeB0cnr5wJ3RsTSiPgcuAY4SlJZI31sAw6TtF9EfBIRS5PXy4FfR8SfI2J7RNwFfA5MaKSP\nk4E3I+KBiNgG3Az8vyZq3gb0BoYBioiVEbEmh/1cHRFbmli/JGvbvwBKmqizpb4HPBYRf0r6vhHo\nCRzdoLbG/gbWxTjcLZ+yA/QzYOeJ0gPJHK0DEBGbgfXAgEb6OJ1MOL8v6XlJRyWvDwGuTIYjaiXV\nAoOSvhs6EFidtb3IXs4WEc8AtwK/AtZKmiNpv2b2s9G+GlsfETuAqibqbKmGn+OOZFvZn2NTfwPr\nYhzu1hE+JBPOACTjy32B6oYNI2JRREwHvgI8DNyfrFoN/Dwi+mQ99omIeY1sbw2Z4N+5PWUvN7LN\n2RExBjiMzPDM/9q5qqm3NNVXInvb3YCBZD4DyATuPlltv9aCfht+jjv3a7fP0czhbh1hHvAjSaOT\nMfJ/A/4cEZXZjSTtlVyDXpoMO2wEdiSr/w9woaRvJidB95U0TVLvRrb3GHC4pL9Lrmi5lF1DNHub\n45I+ewCfAluztvkR0Jrr78dkbftyMsNHC5N1y4BzJHWXNBU4Put9HwF9JZU20e/9wDRJJyT1Xpn0\n/XIrarSUc7hbu4uIp4H/DTxI5qj6G8BZTTT/AVApaSNwIZnxeiJiMXA+mSGUT4BVNHGyMCLWAWcC\nFWSGfw4GFjSxvf3IfHF8QmbIYz1wQ7LuDjLj/7WSHs5tbwF4hMz4+CfJ/vxd8mUFcBlwClCb7Ft9\nvxHxFpkvwr8m29xlKCci/gJ8H7gFWJf0c0pE/HcLarMuQr5Zh5lZ+vjI3cwshRzuZmYp5HA3M0sh\nh7uZWQoVbOKjfv36RVlZWaE2b2ZWlJYsWbIuIvo3165g4V5WVsbixYsLtXkzs6Ik6f3mW3lYxsws\nlRzuZmYp5HA3M0sh30nGzPJi27ZtVFVVsXXr1kKXkgolJSUMHDiQHj32eCuAJjnczSwvqqqq6N27\nN2VlZWQmrLTWigjWr19PVVUVQ4cObVUfHpYxs7zYunUrffv2dbDngST69u3bpn8FOdzNLG8c7PnT\n1s/S4W5mlkIeczezdjGx4hmqa5u6zWzLDejTkwUzp+Stv/Z08803U15ezj777NN843bicDdrpezw\nKqbg6SjVtVuorJiWt/7KZj6Wt77aKiKICLp1a3zw4+abb+b73/9+i8J9+/btdO/ePV8leljGrLV2\nhldlxbS8HqFa611//fUceuihHHPMMZx99tnceOONvPvuu0ydOpUxY8Zw7LHH8tZbbwEwY8YMLr30\nUo4++mi+/vWv88ADD9T3c8MNNzBu3DhGjhzJddddB0BlZSWHHnooP/zhDxk+fDirV6/moosuYuzY\nsRx++OH17WbPns2HH37I5MmTmTx5MgDz5s1jxIgRDB8+nKuvvrp+O7169eLKK69k1KhRvPLKK/n9\nMHZ+A3X0Y8yYMWFWzIZc/cdGn3dVK1as2GU5359Jc/29+uqrMWrUqNiyZUts3LgxDjrooLjhhhti\nypQp8fbbb0dExMKFC2Py5MkREXHeeefFGWecEdu3b48333wzvvGNb0RExJNPPhnnn39+7NixI7Zv\n3x7Tpk2L559/Pt57772QFK+88kr9NtevXx8REXV1dXH88cfHa6+9lql1yJCoqamJiIjq6uoYNGhQ\nrF27NrZt2xaTJ0+OP/zhDxERAcR9993X5D41/EyT9yyOHDLWwzJmlgoLFixg+vTplJSUUFJSwimn\nnMLWrVt5+eWXOfPMM+vbff755/XPTzvtNLp168Zhhx3GRx99BMBTTz3FU089xRFHHAHA5s2beeed\ndxg8eDBDhgxhwoQJ9e+///77mTNnDnV1daxZs4YVK1YwcuTIXepatGgRkyZNon//zESO5557Li+8\n8AKnnXYa3bt35/TTT2+Xz6PZcJc0CLgb+CoQwJyI+GWDNpPI3BT4veSlhyLip/kt1cysZXbs2EGf\nPn1YtmxZo+v33nvv+ueR3E86Irjmmmu44IILdmlbWVnJvvvuW7/83nvvceONN7Jo0SK+/OUvM2PG\njBZfl15SUpLXcfZsuYy51wFXRsRhwATgYkmHNdLuxYgYnTwc7GbWoSZOnMijjz7K1q1b2bx5M3/8\n4x/ZZ599GDp0KL///e+BTHC/9tpre+znpJNO4s4772Tz5s0AVFdXs3bt2t3abdy4kX333ZfS0lI+\n+ugjnnjiifp1vXv3ZtOmTQCMHz+e559/nnXr1rF9+3bmzZvH8ccfn6/dblKzR+4RsQZYkzzfJGkl\nMABY0c61mVkRG9CnZ16vcBnQp+ce148bN45TTz2VkSNH8tWvfpURI0ZQWlrK3Llzueiii/jZz37G\ntm3bOOussxg1alST/Zx44omsXLmSo446Csic9Lznnnt2O8IeNWoURxxxBMOGDWPQoEFMnDixfl15\neTlTp07lwAMP5Nlnn6WiooLJkycTEUybNo3p06e34ZPIUS4D8zsfQBnwAbBfg9cnAeuB14AngMOb\neH85sBhYPHjw4CZPIpgVA59Q3VVjJ/862qZNmyIi4tNPP40xY8bEkiVLClxR23TICVVJvYAHgcsj\nYmOD1UuBIRGxWdLJwMPAwY18kcwB5gCMHTs2ct22mVkuysvLWbFiBVu3buW8887jyCOPLHRJBZNT\nuEvqQSbY50bEQw3XZ4d9RDwu6TZJ/SJiXf5KNTPbs3vvvbfQJXQazZ5QVWb2mjuAlRHxiybafC1p\nh6TxSb/r81momZnlLpcj94nAD4A3JO28nuhaYDBARNwOnAFcJKkO2AKclYwNmZlZAeRytcxLwB7n\nnoyIW4Fb81WUmZm1jeeWMTNLIU8/YGbt46YRsOGD/PVXOhiueKPJ1bW1tdx77738+Mc/zt82G/Hc\nc8+x1157cfTRR7frdtrK4W5m7WPDBzBrQ/76m1W6x9W1tbXcdtttOYf7zuvBm5q2tynPPfccvXr1\n6vTh7mEZM0uFmTNn8u677zJ69GiuuOIKTjjhBI488khGjBjBI488AjQ+be8dd9zBIYccwvjx4zn/\n/PO55JJLAKipqeH0009n3LhxjBs3jgULFlBZWcntt9/OTTfdxOjRo3nxxRcLuct75CN3M0uFiooK\nli9fzrJly6irq+Ozzz5jv/32Y926dUyYMIFTTz0VgHfeeYe77rqLCRMm8OGHH3L99dezdOlSevfu\nzZQpU+qnJrjsssu44oorOOaYY/jggw846aSTWLlyJRdeeCG9evXiqquuKuTuNsvhbmapExFce+21\nvPDCC3Tr1o3q6ur6KX2zp+199dVXOf7449l///0BOPPMM3n77bcBePrpp1mx4osptDZu3Fg/mVgx\ncLibWerMnTuXmpoalixZQo8ePSgrK6ufjjd72t492bFjBwsXLqSkpKQ9S203HnM3s1TInmZ3w4YN\nfOUrX6FHjx48++yzvP/++42+Z9y4cTz//PN88skn1NXV8eCDD9avO/HEE7nlllvql3fOCZ+9nc7M\nR+5m1j5KBzd7hUuL+9uDvn37MnHiRIYPH864ceN46623GDFiBGPHjmXYsGGNvmfAgAFce+21jB8/\nnv33359hw4ZRWpqpefbs2Vx88cWMHDmSuro6jjvuOG6//XZOOeUUzjjjDB555BFuueUWjj322Pzt\nYx453M2sfezhmvT2ksvEYcuXL99l+ZxzzqG8vJy6ujq++93vctpppwHQr18/7rvvvt3ef8ghh/D6\n66/np+B25GEZM+vSZs2axejRoxk+fDhDhw6tD/di5yN3M+vSbrzxxkKX0C585G5meePJYPOnrZ+l\nw93M8qKkpIT169c74PMgIli/fn2bLsP0sIyZ5cXAgQOpqqqipqam0KWkQklJCQMHDmz1+x3uZpYX\nPXr0YOjQoYUuwxIeljEzSyEfuZu1wMSKZ6iu3QLAgD49C1yNWdMc7mYtUF27hcqKaYUuw6xZHpYx\nM0shh7uZWQo53M3MUsjhbmaWQg53M7MUcribmaWQw93MLIUc7mZmKeRwNzNLIYe7mVkKOdzNzFLI\n4W5mlkLNhrukQZKelbRC0puSLmukjSTNlrRK0uuSjmyfcs3MLBe5zApZB1wZEUsl9QaWSPpTRKzI\navNt4ODk8U3gv5L/NTOzAmj2yD0i1kTE0uT5JmAlMKBBs+nA3ZGxEOgj6YC8V2tmZjlp0Zi7pDLg\nCODPDVYNAFZnLVex+xcAksolLZa02PdZNDNrPzmHu6RewIPA5RGxsTUbi4g5ETE2Isb279+/NV2Y\nmVkOcgp3ST3IBPvciHiokSbVwKCs5YHJa2ZmVgC5XC0j4A5gZUT8oolm84EfJlfNTAA2RMSaPNZp\nZmYtkMvVMhOBHwBvSFqWvHYtMBggIm4HHgdOBlYBnwE/yn+pZmaWq2bDPSJeAtRMmwAuzldRZsVm\nQJ+elM18rP75gplTClyRdXW5HLmbWTOyw3xnyJsVkqcfMDNLIYe7mVkKOdzNzFLI4W5mlkIOdzOz\nFHK4m5mlkMPdzCyFHO5mZinkcDczSyGHu5lZCnn6AbPG3DQCNnwAwBr6c9TWXwKZeWPMioHD3awx\nGz6AWRsAOGBWKZUV0wpckFnLeFjGzCyFHO5mZinkcDczSyGHu5lZCjnczcxSyOFuZpZCDnczsxRy\nuJuZpZDD3cwshRzuZmYp5OkHzHbKmk+G0sGFrcWsjRzuZjtlzSeTrSr6MXBWaWahdDBc8UYHF2bW\nch6WMWvGMZ/PzoT+rA1fHNmbdXIOdzOzFHK4m5mlkMPdzCyFHO5mZinkcDczS6Fmw13SnZLWSlre\nxPpJkjZIWpY8fpL/Ms3MrCVyuc79t8CtwN17aPNiRHwnLxWZmVmbNXvkHhEvAB93QC1mZpYn+Rpz\nP0rSa5KekHR4U40klUtaLGlxTU1NnjZtZmYN5WP6gaXAkIjYLOlk4GHg4MYaRsQcYA7A2LFjIw/b\nNmsXEyueobp2CwAD+vQscDVmLdfmcI+IjVnPH5d0m6R+EbGurX2btbsmJgurrt1CZcW0AhVl1nZt\nDndJXwM+ioiQNJ7MUM/6Nldm1hGamCzMrNg1G+6S5gGTgH6SqoDrgB4AEXE7cAZwkaQ6YAtwVkR4\nyMXMrICaDfeIOLuZ9beSuVTSzMw6Cf9C1cwshRzuZmYp5HA3M0shh7uZWQr5HqpmLVE6GHw/VSsC\nDnezlsgO850hb9YJeVjGzCyFHO5mZinkcDczSyGPuVvXkj1RGOwyWZhZmjjcrWvxRGHWRXhYxsws\nhRzuZmYp5GEZs4TvvmRp4nA3S/juS5YmHpYxM0shh7uZWQo53M3MUsjhbmaWQg53M7MU8tUyZq3l\nud2tE3O4m7WW53a3TszDMmZmKeRwNzNLIQ/LWPplT/PbAVP8DujTk7KZj9U/XzBzSrtv06whh7ul\nXwdP85sd5jtD3qyjeVjGzCyFHO5mZinkcDczSyGHu5lZCjnczcxSqNlwl3SnpLWSljexXpJmS1ol\n6XVJR+a/TDMza4lcjtx/C0zdw/pvAwcnj3Lgv9pelpmZtUWz4R4RLwAf76HJdODuyFgI9JF0QL4K\nNDOzlsvHmPsAYHXWclXy2m4klUtaLGlxTU1NHjZtZmaN6dATqhExJyLGRsTY/v37d+Smzcy6lHyE\nezUwKGt5YPKamZkVSD7mlpkPXCLpd8A3gQ0RsSYP/ZoVD9+4wzqZZsNd0jxgEtBPUhVwHdADICJu\nBx4HTgZWAZ8BP2qvYs3ybWLFM1TXbgEyMzi2mm/cYZ1Ms+EeEWc3sz6Ai/NWkVkHqq7dQmXFtEKX\nYZZ3/oWqmVkKOdzNzFLI4W5mlkIOdzOzFHK4m5mlkMPdzCyFHO5mZinkcDczSyGHu5lZCjnczcxS\nKB8Th5l1PjeNgA0fZJ6XDi5sLWYF4HC3dNrwAczaUOgqzArGwzJmZinkcDczSyGHu5lZCjnczcxS\nyOFuZpZCDnczsxRyuJuZpZCvc7cuJfuG2NDGm2KbdWIOd+tSfENs6yo8LGNmlkIOdzOzFHK4m5ml\nkMfcLT2amAky+ySqT6BaV+Fwt/RoYiZIn0S1rsjhbpZvpYNhVikAL+3dD/AXi3U8h7tZvl3xRv3T\ngUnIm3U0n1A1M0shh7uZWQo53M3MUiincJc0VdJfJK2SNLOR9TMk1Uhaljz+Mf+lmplZrpo9oSqp\nO/Ar4FtAFbBI0vyIWNGg6X0RcUk71GhmZi2Uy9Uy44FVEfFXAEm/A6YDDcPdzBpRNvMxIPMDqgUz\npxS4GusqchmWGQCszlquSl5r6HRJr0t6QNKgxjqSVC5psaTFNTU1rSjXrPhUVkyjsmLaLlMNm7W3\nfF3n/igwLyI+l3QBcBew2yFKRMwB5gCMHTs28rRt68qamHLArKvLJdyrgewj8YHJa/UiYn3W4m+A\n/2x7aWY5aGLKAbOuLpdhmUXAwZKGStoLOAuYn91A0gFZi6cCK/NXopmZtVSzR+4RUSfpEuBJoDtw\nZ0S8KemnwOKImA9cKulUoA74GJjRjjWbmVkzchpzj4jHgccbvPaTrOfXANfktzSz1us00/x6EjEr\nEE8cZqnUaab59SRiViCefsDMLIUc7mZmKeRwNzNLIYe7mVkKOdzNzFLI4W5mlkIOdzOzFHK4m5ml\nkH/EZNZBqqLfFz9kKh28yw+czPLN4W7Fp0in+T3m89lf/GrWv1a1duZwt+LjaX7NmuUxdzOzFPKR\nu6VGp5kJ0qwTcLhbanSamSDNOgEPy5iZpZDD3cwshRzuZmYp5DF3K2rFdBJ1QJ+elM18DIDKkgIX\nY6nncLeiVkwnURfMnPLFwqyClWFdhMPdrAA8FYG1N4e7FYcinXKgKZ6KwNqbw92KQ9aUAxMrnqE6\nGbvu7OPsZoXicLeiU0zj7GaF4kshzcxSyOFuZpZCDnczsxTymLtZAWT/oOmVkv4c4MsiLc8c7mYF\nkP2DprKZ+LJIyzuHu3VeWde2r6E/R/nyR7OcOdytc2n4Y6Xk2vajZj7WNS5/LB38xdG7h2isDXIK\nd0lTgV8C3YHfRERFg/V7A3cDY4D1wPciojK/pVqX0NXvj5od5h6isTZoNtwldQd+BXwLqAIWSZof\nESuymv0P4JOIOEjSWcB/AN9rj4ItJbKP0LNkD79kS/NQTPbJ1Ww+0WptkcuR+3hgVUT8FUDS74Dp\nQHa4T+eLee4eAG6VpIiIPNZqxa7hGPrWe3drMqBPTypnTdnt9TTbZbbILBMretZPZ1zJOV+saDh0\n5dC3RuQS7gOA1VnLVcA3m2oTEXWSNgB9gXXZjSSVA+XJ4mZJf2lN0UC/hn0XsS66LxuB7+z26vuA\nrslnSa3Wqf4uAvhXNbJmOfzPxl6v16n2o428LxlDcmnUoSdUI2IOMKet/UhaHBFj81BSwXlfOqe0\n7Eta9gO8Ly2Vyy9Uq4FBWcsDk9cabSPpS0ApmROrZmZWALmE+yLgYElDJe0FnAXMb9BmPnBe8vwM\n4BmPt5uZFU6zwzLJGPolwJNkLoW8MyLelPRTYHFEzAfuAP6vpFXAx2S+ANpTm4d2OhHvS+eUln1J\ny36A96VF5ANsM7P08ayQZmYp5HA3M0uhog13SddLel3SMklPSTqw0DW1lqQbJL2V7M8fJPUpdE2t\nJelMSW9K2iGp6C5bkzRV0l8krZI0s9D1tJakOyWtlbS80LW0laRBkp6VtCL5b+uyQtfUGpJKJL0q\n6bVkP/61XbdXrGPukvaLiI3J80uBwyLiwgKX1SqSTiRzhVGdpP8AiIirC1xWq0j6G2AH8GvgqohY\nXOCScpZMtfE2WVNtAGc3mGqjKEg6DtgM3B0RwwtdT1tIOgA4ICKWSuoNLAFOK7a/iyQB+0bEZkk9\ngJeAyyJiYXtsr2iP3HcGe2JfoDi/pYCIeCoi6pLFhWR+S1CUImJlRLT2l8eFVj/VRkT8N7Bzqo2i\nExEvkLlyrehFxJqIWJo83wSsJPOr+KISGZuTxR7Jo91yq2jDHUDSzyWtBs4FflLoevLkH4AnCl1E\nF9XYVBtFFyJpJqkMOAL4c2EraR1J3SUtA9YCf4qIdtuPTh3ukp6WtLyRx3SAiPjniBgEzAUuKWy1\ne9bcviRt/hmoI7M/nVYu+2KWb5J6AQ8Clzf4l3vRiIjtETGazL/Ox0tqtyGzTn2zjoj42xybzgUe\nB65rx3LapLl9kTSDzExaJ3T2X/e24O9SbHKZasMKIBmjfhCYGxEPFbqetoqIWknPAlOBdjnp3amP\n3PdE0sFZi9OBtwpVS1slN0P5J+DUiPis0PV0YblMtWEdLDkReQewMiJ+Ueh6WktS/51XwknqSebE\nfbvlVjFfLfMgcCiZKzPeBy6MiKI8ykqmbdibLyZbW1jEV/58F7gF6A/UAssi4qTCVpU7SScDN/PF\nVBs/L3BJrSJpHjCJzNSyHwHXRcQdBS2qlSQdA7wIvEHm/+8A10bE44WrquUkjQTuIvPfVjfg/oj4\nabttr1jD3czMmla0wzJmZtY0h7uZWQo53M3MUsjhbmaWQg53M7MUcribmaWQw93MLIX+P7IsGoa4\nzrIRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "counter 100:\n",
            "[0.206241682 -0.153546721 -0.110187516 -0.0199043732]\n",
            "counter 200:\n",
            "[-0.0672884 -0.501800776 -0.534909427 0.152174383]\n",
            "counter 300:\n",
            "[-0.419731408 -0.140196159 0.0362307318 -0.243897706]\n",
            "counter 400:\n",
            "[0.0862647146 -0.110198691 -0.258512646 -0.098622039]\n",
            "counter 500:\n",
            "[-0.273483157 -0.49730283 -0.800420821 -0.116845533]\n",
            "counter 600:\n",
            "[0.741329074 0.770995617 -1.23939431 0.0270948894]\n",
            "counter 700:\n",
            "[0.563417315 -0.530399621 0.14728561 0.56177181]\n",
            "counter 800:\n",
            "[-0.473774791 -0.468907 -0.933459222 -1.04176605]\n",
            "counter 900:\n",
            "[-0.422228038 -0.107673846 -1.11965585 -0.748519182]\n",
            "counter 1000:\n",
            "[0.0985263 1.31685662 -0.54049021 -0.768211246]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHO5mZinkcDczSyGHu5lZCv1/6Qz3icmukuQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "0.00706374645 -0.518188655\n",
            "Time for epoch 1000,\n",
            "counter 1100:\n",
            "[0.174444631 -0.366561472 -0.164377853 -0.915344536]\n",
            "counter 1200:\n",
            "[0.473552108 -0.780803561 -0.517416 -0.0744131207]\n",
            "counter 1300:\n",
            "[0.870139 0.0126784928 0.121038347 0.0443176664]\n",
            "counter 1400:\n",
            "[-1.3851788 0.31221813 -0.00937726721 0.109979466]\n",
            "counter 1500:\n",
            "[-0.762741268 0.234541431 0.252767086 0.557291031]\n",
            "counter 1600:\n",
            "[-0.649943352 -0.625098228 -0.878175676 -0.758585334]\n",
            "counter 1700:\n",
            "[1.3192755 0.959187388 0.0619509146 0.206908867]\n",
            "counter 1800:\n",
            "[-0.323109984 0.874457657 -0.328202307 1.43059707]\n",
            "counter 1900:\n",
            "[0.585638762 -0.686144888 1.25151658 0.826970279]\n",
            "counter 2000:\n",
            "[-1.30505276 1.15467227 0.939647317 -1.36767459]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOPjNzFLm/wNNFkMoy2fJQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "0.00706374645 -0.518188655\n",
            "Time for epoch 2000,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n",
            "Time for the training is 100.71484708786011 sec,\n",
            "tf.Tensor([-0.5940185   0.52222145  1.2987466   0.12225146], shape=(4,), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 1min 55s, sys: 4.05 s, total: 1min 59s\n",
            "Wall time: 1min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "outputId": "7a48dfb6-bb97-4ae8-ccd0-aadaaa0b5640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator([x])\n",
        "tf.print(real_c.shape)\n",
        "tf.print(fake_c)\n",
        "generator.trainable = False\n",
        "tf.print(generator.trainable)\n",
        "#tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "[[0.138012588 -0.40817064 0.409154266 -0.617667317]\n",
            " [-0.518393636 0.105706491 -0.338086933 -0.179806471]\n",
            " [0.463259399 -0.40019542 -0.125296563 -0.791770935]\n",
            " ...\n",
            " [1.11281061 -0.354023457 -1.07923615 -0.23588571]\n",
            " [0.98226124 0.705134392 0.0131363608 1.21421397]\n",
            " [0.512257 0.0448776856 -0.670382619 1.06856167]]\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschränken. Jedoch soll **end-to-end** trainiert werden, hierfür sollte vllt eine art Funktion eingesetzt werden, welche über die GAN's Layer zurück geht.\n",
        "Muss ich hierfür die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klären: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "da5dc766-97fc-49aa-8888-f42148b3e314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "def B_Ber(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "\n",
        "#def get_encoder():\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "#  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "#  return model\n",
        "\n",
        "#def get_decoder():\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "#  return model\n",
        "\n",
        "#encoder = get_encoder()\n",
        "#decoder = get_decoder()\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "#def test_Model(x):\n",
        "#  y = encoder(x)\n",
        "#  y = generator([y,make_zero(y)])\n",
        "#  y = decoder(y)\n",
        "#  return y\n",
        "  \n",
        "#****************************************************  From  Rick Fritschek \"Communication-via-Autoencoder-TF2\"\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "gen_shape_layer = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "#gen_shape_layer = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "gen_shape_layer2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def decoder(input):\n",
        "  '''The Receiver'''\n",
        "  y = tf.reshape(input, shape=[-1,n])\n",
        "  y = tf.keras.layers.Dense(M, activation='relu')(y)\n",
        "  y = tf.keras.layers.Dense(M, activation=None)(y)\n",
        "  return y\n",
        "\n",
        "\n",
        "\n",
        "def encoder(input):\n",
        "  '''The transmitter'''\n",
        "  #low = np.sqrt(6.0/(2*M)) \n",
        "  #high = -np.sqrt(6.0/(2*M))\n",
        "  #W =tf.random.uniform((M,M), minval=low, maxval=high, dtype=tf.float32)    \n",
        "  #x = tf.nn.elu(tf.nn.embedding_lookup(W, input))\n",
        "  x = tf.keras.layers.Dense(n, activation=None)(input)\n",
        "  x = tf.reshape(x, shape=[-1,int(n/2),2])\n",
        "  #Average power normalization\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) \n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  tf.print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "bl = generate_data_vector(1000)\n",
        "bla =encoder(bl)            #ecoder: (4, 2, 2)\n",
        "blaa =tf.reshape(bla,(tf.shape(bla)[0],-1))\n",
        "blaaa = generator(blaa)\n",
        "blaaaa = tf.reshape(blaaa, shape=[-1,int(n/2),2])\n",
        "blaaaaa = decoder(blaaa)\n",
        "#blaaaaaa =  tf.reshape(blaaaaa, shape=[-1,2*n])\n",
        "\n",
        "print('encoder input',bl.shape)\n",
        "print('encoder output',bla.shape)\n",
        "print('reshaped generator input',blaa.shape)\n",
        "print('generator output',blaaa.shape)\n",
        "print('reshaped generator output',blaaaa.shape)\n",
        "print('decoder output',blaaaaa.shape)\n",
        "#print('reshape decoder',blaaaaaa.shape)\n",
        "\n",
        "#input1 = tf.keras.layers.Input(shape=(n,))\n",
        "#x1 = tf.keras.layers.Dense(n)(input1)\n",
        "\n",
        "'''\n",
        "EncIn = tf.keras.layers.Input(shape=(M,))#, dtype= tf.int32)\n",
        "e1 = tf.keras.layers.Dense(M, activation='relu')(EncIn)\n",
        "e2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))(e1)\n",
        "EncOut = tf.keras.layers.Lambda(lambda x: x/tf.sqrt(2*tf.reduce_mean(tf.square(x))))(e2)\n",
        "GenIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))(EncOut)\n",
        "GenOut = tf.keras.layers.Lambda(generator)(GenIn)\n",
        "DecIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))(GenOut)\n",
        "#out = tf.keras.layers.Lambda(decoder)(DecIn)\n",
        "d1 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,n]))(DecIn)\n",
        "d2 = tf.keras.layers.Dense(M, activation='relu')(d1)\n",
        "DecOut = tf.keras.layers.Dense(M, activation=None)(d2)\n",
        "'''\n",
        "EncIn = tf.keras.layers.Input(shape=(M,))#, dtype= tf.int32)\n",
        "e1 = tf.keras.layers.Dense(n, activation=None)\n",
        "e2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "EncOut = tf.keras.layers.Lambda(lambda x: x/tf.sqrt(2*tf.reduce_mean(tf.square(x))))\n",
        "GenIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "GenOut = tf.keras.layers.Lambda(generator)\n",
        "DecIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "#out = tf.keras.layers.Lambda(decoder)(DecIn)\n",
        "d1 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,n]))\n",
        "d2 = tf.keras.layers.Dense(n, activation='relu')\n",
        "DecOut = tf.keras.layers.Dense(M, activation='softmax')\n",
        "\n",
        "\n",
        "encoder =tf.keras.models.Sequential([EncIn,e1,e2,EncOut,GenIn]) \n",
        "decoder =tf.keras.models.Sequential([DecIn,d1,d2,DecOut])\n",
        "#AE = tf.keras.models.Model(inputs=EncIn, outputs=DecOut)\n",
        "AE = tf.keras.models.Sequential([encoder,generator,decoder])\n",
        "#AE.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#encoder = keras.models.Sequential([\n",
        "#tf.keras.layers.InputLayer(input_shape=[M]),\n",
        "#tf.keras.layers.Dense(M, activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(2*n, activation=None),\n",
        "#shape_layer,\n",
        "#norm_layer])\n",
        "\n",
        "\n",
        "\n",
        "#channel = keras.models.Sequential([channel_layer])\n",
        "\n",
        "#decoder = keras.models.Sequential([tf.keras.layers.InputLayer(input_shape=[2,n]),\n",
        "#shape_layer2,\n",
        "#tf.keras.layers.Dense(M, activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(M, activation=\"softmax\")\n",
        "#])  \n",
        "  \n",
        "#encoder.summary()\n",
        "#generator.summary()\n",
        "#decoder.summary() \n",
        "\n",
        "\n",
        "\n",
        "#def get_AE():\n",
        "#  AE_model = tf.keras.Sequential()\n",
        "#  AE_model.add(tf.keras.layers.Lambda(encoder))\n",
        "#  AE_model.add(gen_shape_layer)\n",
        "#  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "#  AE_model.add(gen_shape_layer2)\n",
        "#  AE_model.add(tf.keras.layers.Lambda(decoder))\n",
        " # return AE_model\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  tf.print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(10000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "#AE = get_AE()\n",
        "#tf.keras.optimizers.Adam(learning_rate=0.001, epsilon= 0.00001)\n",
        "AE.compile(optimizer='adam',loss=tf.keras.losses.categorical_crossentropy,metrics=[B_Ber])\n",
        "history = AE.fit(data, data, batch_size=1000,steps_per_epoch=100, epochs=6)\n",
        "\n",
        "AE.summary()\n",
        "\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "encoder input (1000, 4)\n",
            "encoder output (1000, 2, 2)\n",
            "reshaped generator input (1000, 4)\n",
            "generator output (1000, 4)\n",
            "reshaped generator output (1000, 2, 2)\n",
            "decoder output (1000, 4)\n",
            "TensorShape([10000000, 4])\n",
            "TensorShape([10000, 4])\n",
            "Train on 10000000 samples\n",
            "Epoch 1/8\n",
            "  100000/10000000 [..............................] - ETA: 4:22 - loss: 0.7313 - B_Ber: 0.2128Epoch 2/8\n",
            "   99200/10000000 [..............................] - ETA: 2:18 - loss: 0.2144 - B_Ber: 4.5363e-04Epoch 3/8\n",
            "   98200/10000000 [..............................] - ETA: 2:15 - loss: 0.0979 - B_Ber: 1.5275e-04Epoch 4/8\n",
            "   96400/10000000 [..............................] - ETA: 2:17 - loss: 0.0557 - B_Ber: 4.1494e-05Epoch 5/8\n",
            "  100000/10000000 [..............................] - ETA: 2:18 - loss: 0.0345 - B_Ber: 6.0000e-05Epoch 6/8\n",
            "   99600/10000000 [..............................] - ETA: 2:12 - loss: 0.0233 - B_Ber: 5.0201e-05Epoch 7/8\n",
            "   97400/10000000 [..............................] - ETA: 2:09 - loss: 0.0165 - B_Ber: 5.1335e-05Epoch 8/8\n",
            "   98000/10000000 [..............................] - ETA: 2:10 - loss: 0.0118 - B_Ber: 4.0816e-05Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1 (Sequential)    (None, None)              20        \n",
            "_________________________________________________________________\n",
            "model (Model)                (None, 4)                 1516      \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    multiple                  40        \n",
            "=================================================================\n",
            "Total params: 1,576\n",
            "Trainable params: 60\n",
            "Non-trainable params: 1,516\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "outputId": "588114bf-2e49-4149-eef6-dcbe50dfd758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.print(sum(diff_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 4 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "outputId": "7f623d82-c728-4527-d6e1-821ab8cdf06e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAD8CAYAAAC/+/tYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADU1JREFUeJzt3W2MpeVdx/Hvzy1bE0qkClKE3YJx\nU1y1SjsBJvhidFsDpAFbSwIv2tKHkBiIbdLEoE1qYl9sjUlNGkgrKaTFkELTFsWwla5bJtg4IANZ\nHrfYlWjYdZUnA22o3ez274tzoOMyszNc99lz7jP7/SQn97nvc819XWd35pfrfjjnn6pCklr8zKQH\nIGl6GSCSmhkgkpoZIJKaGSCSmhkgkpp1DpAkm5Lck+SJJI8n+fgybZLk80n2JnkkyTu69itp8t4w\ngn0cAj5ZVQ8lOQl4MMnOqnpiSZuLgS3Dx/nAF4ZLSVOs8wykqg5U1UPD5z8A9gBnHNHsMuCWGrgP\nODnJ6V37ljRZo5iBvCrJWcC5wP1HvHQG8PSS9X3DbQeW2cfVwNUAJ5544jvPOeecUQ5R0ho8+OCD\nz1XVqau1G1mAJHkT8A3gE1X1Uut+qupG4EaAmZmZWlxcHNEIJa1Vkv9YS7uRXIVJcgKD8Li1qr65\nTJP9wKYl62cOt0maYqO4ChPgJmBPVX1uhWZ3Ah8cXo25AHixql5z+CJpuoziEOZC4APAo0l2D7f9\nKbAZoKq+COwALgH2Ai8DHx5Bv5ImrHOAVNV3gazSpoBruvYlqV+8E1VSMwNEUjMDRFIzA0RSMwNE\nUjMDRFIzA0RSMwNEUjMDRFIzA0RSMwNEUjMDRFIzA0RSMwNEUjMDRFIzA0RSMwNEUjMDRFKzUX0r\n+81Jnkny2AqvzyV5Mcnu4ePTo+hX0mSNqi7Ml4HrgVuO0uafquo9I+pPUg+MZAZSVfcCL4xiX5Km\nxzjPgcwmeTjJt5L82hj7lXSMjLQ27lE8BLy1qn6Y5BLgb4EtyzVcWht38+bNYxqepBZjmYFU1UtV\n9cPh8x3ACUlOWaHtjVU1U1Uzp566am1fSRM0lgBJ8pZhCUySnDfs9/lx9C3p2BnJIUySrwJzwClJ\n9gF/BpwAr5a2fD/wh0kOAT8CrhhWq5M0xUYSIFV15SqvX8/gMq+kdcQ7USU1M0AkNTNAJDUzQCQ1\nM0AkNTNAJDUzQCQ1M0AkNTNAJDUzQCQ1M0AkNTNAJDUzQCQ1M0CmxMICbN8+WEp9Ma6vNFQHCwuw\nbRscPAgbN8KuXTA7O+lRSc5ApsL8/CA8Dh8eLOfnJz2i/nKmNl7OQKbA3Nxg5vHKDGRubtIj6idn\nauNngEyB2dnBH8P8/CA8/KNY3nIzNf+tji0DZErMzvrHsBpnauM3rtq4SfL5JHuTPJLkHaPoV1rq\nlZnaZz7j4cu4jKs27sUMCkltAc4HvjBcSiPlTG28xlUb9zLglhq4Dzg5yemj6FvS5IzrMu4ZwNNL\n1vcNt71GkquTLCZZfPbZZ8cyOEltencfiKUtpekxrgDZD2xasn7mcJukKTauALkT+ODwaswFwItV\ndWBMfUs6RsZVG3cHcAmwF3gZ+PAo+pU0WeOqjVvANaPoS1J/9O4kqqTpYYBIamaASGpmgEhqZoBI\namaASGpmgEhqZoBIamaASGpmgEhqZoBIamaASGpmgEhqZoBIamaASGpmgEhqZoBIamaASGo2qtKW\nFyV5cli68rplXr8qybNJdg8fHxtFv5Imq/N3oibZANwAvJtBwagHktxZVU8c0fT2qrq2a3+S+mMU\nM5DzgL1V9VRVHQRuY1DKUtI6N4oAWWvZyj9I8kiSryfZtMzrgKUtpWkyrpOofw+cVVVvB3YCX1mp\noaUtpekxigBZtWxlVT1fVT8ern4JeOcI+pU0YaMIkAeALUnOTrIRuIJBKctXJTl9yeqlwJ4R9Ctp\nwjpfhamqQ0muBe4GNgA3V9XjSf4cWKyqO4E/SnIpcAh4Abiqa7+SJi+DqpP9NDMzU4uLi5MehnTc\nSfJgVc2s1s47USU1M0AkNTNAJDUzQCQ1M0AkNTNAJDUzQCQ1M0AkNTNAJDUzQCQ1M0AkNTNAJDUz\nQCQ1M0AkNTNAJDUzQCQ1M0AkNTNAJDUbV2nLNya5ffj6/UnOGkW/kiarc4AsKW15MbAVuDLJ1iOa\nfRT4n6r6FeCvgL/o2q+kyRtXacvL+Gkxqa8D25JkBH1LmqBxlbZ8tU1VHQJeBH5huZ1Z2lKaHr07\niWppS2l6jKW05dI2Sd4A/Bzw/Aj6ljRBYyltOVz/0PD5+4HvVJ8rWklak3GVtrwJ+JskexmUtryi\na7+SJq9zgABU1Q5gxxHbPr3k+f8Cl4+iL0n90buTqJKmhwEiqZkBcpxbWIDt2wdL6fUayTkQTaeF\nBdi2DQ4ehI0bYdcumJ2d9Kg0TZyBHMfm5wfhcfjwYDk/P+kRadoYIMexubnBzGPDhsFybm7SI9K0\n8RDmODY7OzhsmZ8fhIeHL3q9DJDj3OyswaF2HsJIamaASGpmgEhqZoBIamaASGpmgEhqZoBIamaA\nSGpmgEhqZoBIatYpQJL8fJKdSb4/XL55hXaHk+wePo78wmVJU6rrDOQ6YFdVbQF2DdeX86Oq+q3h\n49KOfUrqia4BsrRk5VeA3++4P0lTpGuAnFZVB4bP/ws4bYV2PzssV3lfkqOGjKUtpemx6sf5k/wj\n8JZlXvrU0pWqqiQrFYt6a1XtT/LLwHeSPFpV/7Zcw6q6EbgRYGZmxuJTUo+tGiBV9a6VXkvy30lO\nr6oDSU4HnllhH/uHy6eSzAPnAssGiKTp0fUQZmnJyg8Bf3dkgyRvTvLG4fNTgAuBJzr2K6kHugbI\nZ4F3J/k+8K7hOklmknxp2OZXgcUkDwP3AJ+tKgNEWgc6faVhVT0PbFtm+yLwseHzfwZ+o0s/kvrJ\nO1ElNTNAJDUzQCQ1M0AkNTNAJDUzQCQ1M0AkNTNAJDUzQCQ1M0DUOwsLsH37YKl+63QruzRqCwuw\nbRscPAgbN8KuXTA7O+lRaSXOQNQr8/OD8Dh8eLCcn5/0iHQ0Boh6ZW5uMPPYsGGwnJub9Ih0NB7C\nqFdmZweHLfPzg/Dw8KXfDBD1zuyswTEtPISR1MwAkdTMAJHUrGtpy8uTPJ7kJ0lmjtLuoiRPJtmb\nZKXqdZKmTNcZyGPA+4B7V2qQZANwA3AxsBW4MsnWjv1K6oGuX6q8ByDJ0ZqdB+ytqqeGbW9jUBLT\nb2aXptw4zoGcATy9ZH3fcNuyLG0pTY9OpS2r6jWFpLqytKU0PTqVtlyj/cCmJetnDrdJmnLjOIR5\nANiS5OwkG4ErGJTElDTlul7GfW+SfcAscFeSu4fbfynJDoCqOgRcC9wN7AG+VlWPdxu2pD7oehXm\nDuCOZbb/J3DJkvUdwI4ufUnqH+9EldTMAJHUzACR1MwAkdTMAJHUzACR1MwAkdTMAJHUzACR1MwA\nkdTMAJHUzACR1MwAkdTMAJHUzACR1MwAkdTMAJHUzACR1GxcpS3/PcmjSXYnWezSp6T+6PSdqPy0\ntOVfr6Ht71TVcx37k9Qj4yhtKWmdGtc5kAK+neTBJFePqU9Jx9i4Slv+dlXtT/KLwM4k36uqe1fo\n72rgaoDNmzevcfeSJmEcpS2pqv3D5TNJ7gDOA5YNEGvjStPjmB/CJDkxyUmvPAd+j8HJV0lT7piX\ntgROA76b5GHgX4C7quofuvQrqR+OeWnLqnoK+M0u/UjqJ+9EldTMAJHUzACR1MwAkdTMAJHUzACR\n1MwAkdTMAJHUzACR1MwAkdTMAJHUzACR1MwAkdTMAJHUzACR1MwAkdTMAJHUzACR1MwAkdSs65cq\n/2WS7yV5JMkdSU5eod1FSZ5MsjfJdV36lNQfXWcgO4Ffr6q3A/8K/MmRDZJsAG4ALga2Alcm2dqx\nX0k90ClAqurbVXVouHofcOYyzc4D9lbVU1V1ELgNuKxLv5L6oVNZhyN8BLh9me1nAE8vWd8HnL/S\nTpaWtgR+nGS9FqE6BXhu0oM4hnx/0+1ta2k0ktq4ST4FHAJufT0jXM7S0pZJFqtqpus++2g9vzfw\n/U27JItrade5Nm6Sq4D3ANuqarlatvuBTUvWzxxukzTlul6FuQj4Y+DSqnp5hWYPAFuSnJ1kI3AF\ncGeXfiX1Q9erMNcDJwE7k+xO8kX4/7VxhydZrwXuBvYAX6uqx9e4/xs7jq/P1vN7A9/ftFvT+8vy\nRx2StDrvRJXUzACR1KzXAbLWW+WnVZLLkzye5CdJ1s0lwfX80YUkNyd5Zj3en5RkU5J7kjwx/L38\n+Go/0+sAYQ23yk+5x4D3AfdOeiCjchx8dOHLwEWTHsQxcgj4ZFVtBS4Arlnt/67XAbLGW+WnVlXt\nqaonJz2OEVvXH12oqnuBFyY9jmOhqg5U1UPD5z9gcNX0jKP9TK8D5AgfAb416UFoVct9dOGov4Tq\nnyRnAecC9x+t3Sg/C9Nk3LfKj9ta3p/UJ0neBHwD+ERVvXS0thMPkBHcKt9rq72/dciPLkyxJCcw\nCI9bq+qbq7Xv9SHMGm+VV7/40YUplSTATcCeqvrcWn6m1wHCCrfKrxdJ3ptkHzAL3JXk7kmPqauO\nH13ovSRfBRaAtyXZl+Sjkx7TCF0IfAD43eHf2+4klxztB7yVXVKzvs9AJPWYASKpmQEiqZkBIqmZ\nASKpmQEiqZkBIqnZ/wH7CAng6ySuUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8o3nqP_0OTK",
        "colab_type": "code",
        "outputId": "ea62d3a1-df87-41ba-f90a-1000d1e56baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= AE.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAD8CAYAAAC/+/tYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEnN/g9PKPia3nVDmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}